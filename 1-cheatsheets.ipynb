{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd70929-7442-42e6-b7a9-0fb0dacd8ccc",
   "metadata": {},
   "source": [
    "# Unit 1: Linear Algebra, Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a5f2e-b4d3-404b-8df5-e036c113a3d8",
   "metadata": {},
   "source": [
    "## Setting the context\n",
    "### Systems of differential equations arise naturally from many physical scenarios. Additionally, any higher order ODE (or system of such) can be written as a system of first-order ODEs. (This is called finding the companion matrix.) This is useful because MATLAB and other computer algebra systems have routines for solving systems of first order ODEs!\n",
    "\n",
    "### Here is where linear algebra enters the stage. Let's review how linear algebra came into play in solving 2x2 systems, so we can outline the goals of our understanding of linear algebra for the context of solving differential equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8224242-0028-4f4b-b441-d1d26530c2a5",
   "metadata": {},
   "source": [
    "## Review of solving $2 \\times 2$ systems of DEs\n",
    "### Given a system of differential equations, our first step is to write this system as a matrix system\n",
    "## $$ \\bf{\\dot{x}} = \\bf{A} \\bf{x} + \\bf{b} $$\n",
    "\n",
    "### For now, we assume $\\bf{b} = \\bf{0}$, as we will not handle solving the inhomogeneous case until we've developed tools from linear algebra to help us in this endeavor.\n",
    "### The process for solving the system $\\bf{\\dot{x}} = \\bf{A} \\bf{x}$ which has distinct eigenvalues is as follows:\n",
    "\n",
    "### ***Step 1***: Find the eigenvalues of $\\bf{A}$. (Find $\\lambda_1, \\lambda_2$ that solves $\\det(\\bf{A} - \\lambda \\bf{I}) = \\bf{0}$.)\n",
    "### ***Step 2***: Find the eigenvectors of $\\bf{A}$ corresponding to each eigenvalue. (Find $\\bf{v_1}, \\bf{v_2}$ that solve $(\\bf{A} - \\lambda \\bf{I}) \\bf{v} = \\bf{0}$ for each $\\lambda_i, i = 1,2$.)\n",
    "### ***Step 3***: Solutions take the form\n",
    "## $$ \\bf{x}(t) = c_1 e^{\\lambda_1 t} \\bf{v_1} + c_2 e^{\\lambda_2 t} \\bf{v_2} $$\n",
    "\n",
    "### for arbitrary constants $c_1$ and $c_2$ which can be determined from initial conditions.\n",
    "\n",
    "### The process of solving homogenous higher order systems of differential equations consists of the same steps if there are distinct eigenvalues. The key issues are that we must now expand our linear algebra toolbox to handle solutions to linear systems, linear independence, determinants, eigenvalues and eigenvectors, and more in $3$ or more dimensions. We will also be able to use these tools to solve systems with repeated eigenvalues. That is the goal of the next several lectures.\n",
    "\n",
    "### We will develop our linear algebra toolbox both by hand on paper and with computer aid MATLAB in tandem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bbf14-edee-4706-a605-b3322a267b6d",
   "metadata": {},
   "source": [
    "## Geometry of linear systems\n",
    "### Given a system of $2$ equations with $2$ unknowns, each equation describes a line.\n",
    "## $$ a x + b y = 8 $$\n",
    "## $$ c x+ d y = 2 $$\n",
    "### The solution is the intersection of the solutions to each equation independently. There are 3 possibilities for the solution to such a system:\n",
    "![Solutions](img/solutions.png)\n",
    "\n",
    "### Given a system of $3$ equations and $3$ unknowns, it is more complicated â€“ the solution can be a point, a line, a plane, or nothing!\n",
    "\n",
    "### Beyond equations with 3 unknowns, we have a hard time visualizing the solutions spaces geometrically. Instead, it is helpful to have algorithmic approaches to finding solutions. Part of this approach will involve writing our systems in terms of matrices. In this lecture, we will focus on developing an algorithm for finding solutions when there is one solution, a line of solutions, no solution. This same approach works in other situations, as seen in the complicated example at the end of this lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4f3a9-9ce3-4af9-afbf-dfcb7ed78827",
   "metadata": {},
   "source": [
    "## Writing systems in matrix form\n",
    "\n",
    "### A system of $3$ equations with $3$ unknowns,\n",
    "## $$ 8y-4z=0 $$\n",
    "## $$ x-y-4z=1$$\n",
    "## $$ -x+5y+2z = 0 $$\n",
    "### can be rewritten in matrix form as $\\bf{A}\\bf{x} = \\bf{b}$:\n",
    "## $$ \\underset{\\bf{A}}{\\begin{pmatrix} 0 & 8 & -4 \\\\ 1 & -1 & -4 \\\\ -1 & 5 & 2 \\end{pmatrix}} \\underset{\\bf{x}}{\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix}} = \\underset{\\bf{b}}{\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}} $$\n",
    "\n",
    "### We can think of multiplying the vector $\\bf{x}$ and the matrix $\\bf{A}$ in $2$ equivalent ways as follows:\n",
    "\n",
    "### ***1.*** To multiply $\\bf{A}$ and $\\bf{x}$ to get a vector $\\bf{B}$, the th entry of $\\bf{B}$ is the dot product of the $i$th row of $\\bf{A}$ with $\\bf{x}$.\n",
    "\n",
    "## $$ \\begin{pmatrix} 0 & 8 & -4 \\\\ 1 & -1 & -4 \\\\ -1 & 5 & 2 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} 8y-4z \\\\ x-y-4z \\\\ -1x+5y+2z \\end{pmatrix} $$\n",
    "\n",
    "### This explains why the matrix form is equivalent to the original system of equations.\n",
    "\n",
    "### ***2.*** The product $\\bf{A}\\bf{x}$ can be expressed as a linear combination of the columns of $\\bf{A}$:\n",
    "## $$ \\begin{pmatrix} 0 & 8 & -4 \\\\ 1 & -1 & -4 \\\\ -1 & 5 & 2 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = x \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\end{pmatrix} + y \\begin{pmatrix} 8 \\\\ -1 \\\\ 5 \\end{pmatrix} + z \\begin{pmatrix} -4 \\\\ -4 \\\\ 2 \\end{pmatrix} $$\n",
    "\n",
    "### Notice that the coefficients $x$, $y$, and $z$ in this linear combination are the entries of the vector $\\bf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12b1c2-f04b-4c49-be17-9b9c08627d65",
   "metadata": {},
   "source": [
    "## Matrix notation and matrix algebra\n",
    "\n",
    "### We will start with the novice view of a matrix as a table of numbers:\n",
    "## $$ \\begin{pmatrix} 1 & 3 & 3 & 0 & 3 \\\\ 3 & 47 & 3 & 8 & 38 \\\\ 8 & 3 & 0 & 0 & 0 \\\\ 0 & 0 & 32 & 4 & 3 \\\\ 1 & 2 & 1 & 0 & 1 \\end{pmatrix} $$\n",
    "\n",
    "### If we do not know what these numbers are, or wish to describe a generic matrix, we may choose to use variables instead:\n",
    "## $$ \\begin{pmatrix} a & b & c & d & e \\\\ f & g & h & i & j \\\\ k & l & m & n & o \\\\ p & q & r & s & t \\\\ u & v & w & x & y \\end{pmatrix} $$\n",
    "\n",
    "### However, as our matrices get larger and larger, we tend to run out of letters pretty quickly. Instead, use a single letter and subscripts to denote its location within the matrix. We say a matrix $\\bf{a}$ is $m \\times n$ if it has $m$ rows and $n$ columns. We denote the entry in the $i$th row and $j$th column by $a_{ij}$, and write the full matrix as\n",
    "## $$ \\begin{array} \\ \\phantom{a} \\\\ \\phantom{a} \\\\ \\phantom{a} \\\\ \\color{red}{\\text{row}\\, i} \\\\ \\phantom{a} \\\\ \\phantom{a} \\\\ \\end{array} \\begin{array} \\ \\begin{array} \\ \\phantom{a} & \\phantom{a} & \\phantom{a} & \\color{red}{\\text{column}\\, j} & \\phantom{a} & \\phantom{a} \\end{array} \\\\ \\begin{pmatrix} a_{11} & a_{12} & \\cdots & {\\color{red}{|}} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & {\\color{red}{|}} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\cdots & {\\color{red}{|}} & \\cdots & \\vdots \\\\ {\\color{red}{-}} & {\\color{red}{-}} & {\\color{red}{-}} & {\\color{red}{a_{ij}}} & {\\color{red}{-}} & {\\color{red}{-}} \\\\ \\vdots & \\vdots & \\cdots & {\\color{red}{|}} & \\cdots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & {\\color{red}{|}} & \\cdots & a_{mn} \\end{pmatrix} \\end{array} $$\n",
    "\n",
    "### In this course, we will mostly be concerned with square matrices, which are matrices whose number of rows is equal to the number of columns.\n",
    "\n",
    "### We can think of multiplying vectors and matrices in 2 equivalent ways as follows:\n",
    "\n",
    "### ***1.*** To multiply $\\bf{A}$ and $\\bf{x}$ to get a vector $\\bf{b}$, the $j$th entry of $\\bf{b}$ is the dot product of the $j$th row of $\\bf{A}$ with $\\bf{x}$.\n",
    "## $$ \\begin{pmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\cdots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{pmatrix} \\begin{pmatrix} \\color{red}{x_1} \\\\ \\color{red}{x_2} \\\\ \\vdots \\\\ \\color{red}{x_n} \\end{pmatrix} = \\begin{pmatrix} a_{11} \\color{red}{x_1} & a_{12} \\color{red}{x_2} & \\cdots & a_{1n}\\color{red}{x_n} \\\\ a_{21}\\color{red}{x_1} & a_{22}\\color{red}{x_2} & \\cdots & a_{2n}\\color{red}{x_n} \\\\ \\vdots & \\vdots & \\cdots & \\vdots \\\\ a_{m1}\\color{red}{x_1} & a_{m2}\\color{red}{x_2} & \\cdots & a_{mn}\\color{red}{x_n} \\end{pmatrix}  $$\n",
    "\n",
    "### ***2.*** The product $\\bf{A}\\bf{x}$ can be expressed as a linear combination of the columns of $\\bf{A}$:\n",
    "## $$ \\begin{pmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\cdots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{pmatrix} \\begin{pmatrix} \\color{red}{x_1} \\\\ \\color{red}{x_2} \\\\ \\vdots \\\\ \\color{red}{x_n} \\end{pmatrix} = {\\color{red}{x_1}} \\begin{pmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{m1} \\end{pmatrix} + {\\color{red}{x_2}} \\begin{pmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\end{pmatrix} + \\cdots + {\\color{red}{x_n}} \\begin{pmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\end{pmatrix} $$\n",
    "\n",
    "### where the coefficients are the entries of the vector $\\bf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27d972-1d81-4ebb-9d20-38c8a32e407f",
   "metadata": {},
   "source": [
    "## Properties of matrix vector multiplication\n",
    "\n",
    "### ***0.*** For any matrix $\\bf{A}$, and the zero vector $\\bf{0}$:\n",
    "## $$ \\bf{A} \\bf{0} = \\bf{0} $$\n",
    "### ***1.*** For any matrix $\\bf{A}$, a $c$ scalar, and a vector $\\bf{x}$:\n",
    "## $$ \\bf{A} (c \\bf{x}) = c (\\bf{A} \\bf{x}) $$\n",
    "### ***2.*** For any matrix $\\bf{A}$, and vectors $\\bf{x}$ and $\\bf{y}$:\n",
    "## $$ \\bf{A} (\\bf{x} + \\bf{y}) = \\bf{A} \\bf{x} + \\bf{A} \\bf{y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5ec0d-697d-4b54-ad6b-079f1bf45526",
   "metadata": {},
   "source": [
    "## Matrices as functions\n",
    "\n",
    "### Another view of an $m \\times n$ matrix that will be useful for us is to think of it as a function from $\\mathbb{R}^n$ to $\\mathbb{R}^m$.\n",
    "\n",
    "### ***Example 5.1***\n",
    "### Consider the matrix $\\bf{A} = \\begin{pmatrix} 1 & 2 \\\\ 4 & 7 \\\\ 8 & 9 \\end{pmatrix} $ as a function $\\bf{f}$ from $\\mathbb{R}^2$ to $\\mathbb{R}^3$. To evaluate $\\bf{f}$ at $\\bf{v} = \\begin{pmatrix} 10 \\\\ 1 \\end{pmatrix}$, we multiply the vector $\\bf{v}$ by the matrix $\\bf{A}$:\n",
    "## $$ \\begin{pmatrix} 1 & 2 \\\\ 4 & 7 \\\\ 8 & 9 \\end{pmatrix} \\begin{pmatrix} {\\color{red}{10}} \\\\ {\\color{red}{1}} \\end{pmatrix} = \\begin{pmatrix} 1({\\color{red}{10}}) + 2 ({\\color{red}{1}}) \\\\ 4 ({\\color{red}{10}}) + 7 ({\\color{red}{1}}) \\\\ 8 ({\\color{red}{10}}) + 9 ({\\color{red}{1}}) \\end{pmatrix} = \\begin{pmatrix} 12 \\\\ 47 \\\\ 89 \\end{pmatrix} $$\n",
    "### The result is a vector with $3$ entries; a vector in $\\mathbb{R}^3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941bf61-b620-42d4-aa99-d6ca0975a78b",
   "metadata": {},
   "source": [
    "## The geometry of matrices as functions\n",
    "\n",
    "### Imagine evaluating an $m \\times n$ matrix $\\bf{A}$ on every vector in the input space $\\mathbb{R}^n$, to get vectors in the output space $\\mathbb{R}^m$. To visualize it, draw a shape in the input space, apply $\\bf{A}$ to every point in the shape, and plot the output points in the output space.\n",
    "\n",
    "### ***Problem 6.1***\n",
    "### The matrix $\\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}$ represents a function $\\bf{f}$ from $\\mathbb{R}^2$ to $\\mathbb{R}^2$. Determine what it does to the ***standard basis*** vectors $\\bf{e_1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\, \\bf{e_2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ of $\\mathbb{R}^2$. Then depict what happens to a smiley face of unit area under this matrix function.\n",
    "\n",
    "### ***Solution***: \n",
    "### We have\n",
    "## $$ \\bf{f} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} $$\n",
    "## $$ \\bf{f} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n",
    "\n",
    "### and the smiley with unit radius is stretched horizontally into a wide smiley of the same height.\n",
    "![Smiley](img/smiley.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d847a-1d45-4ee2-bcd3-656ae15a26dd",
   "metadata": {},
   "source": [
    "## Mathlet: [https://mathlets.org/mathlets/matrix-vector/](https://mathlets.org/mathlets/matrix-vector/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc4436-76fb-4b68-8254-6e6b913cd1c5",
   "metadata": {},
   "source": [
    "## Representing functions with matrices\n",
    "\n",
    "### It turns out that if we have a function from $\\mathbb{R}^n$ to $\\mathbb{R}^m$ that we know comes from multiplication on the left with a matrix $\\bf{A}$, we can find this matrix by looking at where this matrix sends the standard basis vectors!\n",
    "\n",
    "### ***Problem 7.1*** \n",
    "### Given $\\theta$, there is a $2 \\times 2$ matrix $\\bf{R}$ whose associated function rotates each vector in $\\mathbb{R}^2$ counterclockwise by the angle $\\theta$. What is it?\n",
    "![Rotation](img/rotation.png)\n",
    "\n",
    "### ***Solution***: \n",
    "### The rotation maps $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ to $\\begin{pmatrix} \\cos{\\theta} \\\\ \\sin{\\theta} \\end{pmatrix}$ and $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $ to $\\begin{pmatrix} -\\sin{\\theta} \\\\ \\cos{\\theta} \\end{pmatrix} $. We know that the matrix with columns $\\bf{R} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} $ and $\\bf{R} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $ is the matrix we want, and that this approach for finding a matrix representing a function always works. Thus\n",
    "## $$ (\\text{first column of }\\, \\bf{R}) = \\bf{R} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\cos{\\theta} \\\\ \\sin{\\theta} \\end{pmatrix} $$\n",
    "## $$ (\\text{second column of }\\, \\bf{R}) = \\bf{R} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -\\sin{\\theta} \\\\ \\cos{\\theta} \\end{pmatrix} $$\n",
    "### so\n",
    "## $$ \\bf{R} = \\begin{pmatrix} \\cos{\\theta} & -\\sin{\\theta} \\\\ \\sin{\\theta} & \\cos{\\theta} \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b863e-54f8-43fc-8349-def7d9548c97",
   "metadata": {},
   "source": [
    "## Rotation in three dimensions\n",
    "\n",
    "### What is the matrix $\\bf{A}$ which rotates the $xy$-plane in $\\mathbb{R}^3$ counterclockwise by an angle $\\theta$ about the $z$-axis?\n",
    "\n",
    "![3D Rotation](img/3d-rotation.png)\n",
    "\n",
    "### ***Solution***:\n",
    "### The $z$-axis is fixed by this rotation, so\n",
    "## $$ \\bf{A} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} $$\n",
    "### On the other hand, the $x$ and $y$ basis vectors rotate by $\\theta$ in the plane, but still don't have a $z$-coordinate after the rotation; only their $x$ and $y$ components change. So, similar to the example above,\n",
    "\n",
    "## $$ \\bf{A} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\cos{\\theta} \\\\ \\sin{\\theta} \\\\ 0 \\end{pmatrix} $$\n",
    "## $$ \\bf{A} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -\\sin{\\theta} \\\\ \\cos{\\theta} \\\\ 0 \\end{pmatrix} $$\n",
    "## $$ \\bf{A} = \\begin{pmatrix} \\cos{\\theta} & -\\sin{\\theta} & 0 \\\\ \\sin{\\theta} & \\cos{\\theta} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ced85d-eaa0-48d2-9a4f-93dad459c4f9",
   "metadata": {},
   "source": [
    "### ***Geometric examples in*** $\\mathbb{R}^3$:\n",
    "### Here are some functions from $\\mathbb{R}^3$ to $\\mathbb{R}^3$ that can be represented as a matrix: reflections across a plane through the origin, rotations about a line through the origin, and projections onto a plane or line through the origin.\n",
    "\n",
    "### ***Nonexample***:\n",
    "### A function from $\\mathbb{R}^3$ to $\\mathbb{R}^3$ which translates all points by a fixed amount cannot be represented by multipliction by a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11648759-d5e0-4ee1-980d-31c59808e9fe",
   "metadata": {},
   "source": [
    "## When can a function be represented by a matrix?\n",
    "\n",
    "### A matrix represents a very special kind of function called a ***linear transformation***.\n",
    "### A function $\\bf{f} : \\mathbb{R}^n \\to \\mathbb{R}^m$ is a ***linear transformation*** if:\n",
    "### ***0.*** â€ƒ it maps the zero vector in $\\mathbb{R}^n$ to the zero vector in $\\mathbb{R}^m: \\bf{F}(\\bf{0}) = 0$,\n",
    "### ***1.*** â€ƒ for a vector $\\bf{v}$ and a constant $c$, $\\bf{f}(c \\bf{v}) = c \\bf{f}(\\bf{v})$, and\n",
    "### ***2.*** â€ƒ for vectors $\\bf{v}$ and $\\bf{w}$ in $\\mathbb{R}^n$, $\\bf{f}(\\bf{v} + \\bf{w}) = \\bf{f}(\\bf{v}) + \\bf{f}(\\bf{w})$.\n",
    "\n",
    "### What this means roughly is that the function preserves vector addition and multiplication by a scalar. In pictures, we could draw this the following way.\n",
    "![Linear Transformation](img/ltran-1.png)\n",
    "### If you take two vectors and add them, then take the linear transformation, this is the same as first taking the linear transformation of each of the two vectors, and then adding them.\n",
    "![Linear Transformation](img/ltran-2.png)\n",
    "\n",
    "### Any function that is a linear transformation can be represented by a matrix by the method described above in the text.\n",
    "### To learn more about linear transformations, you may want to watch the following video.\n",
    "## [Linear transformations and matrices](https://www.youtube.com/watch?v=kYB8IZa5AuE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aaea05-1299-44d7-a70f-e7fbbf409bfd",
   "metadata": {},
   "source": [
    "## Augmented matrix and row operations\n",
    "\n",
    "### ***Example 8.1***\n",
    "### Consider the following system.\n",
    "## $$ 8y-4z=0 $$\n",
    "## $$ x-y+4z=1 $$\n",
    "## $$ -x-5y+2z=0 $$\n",
    "\n",
    "### We can encode all the information of this system in this ***augmented matrix***, which is a new matrix with one extra column formed by putting the vector $\\bf{b}$ on the right side of the matrix $\\bf{A}$:\n",
    "## $$ \\left( \\begin{array} {c|c} \\bf{A} & \\bf{b} \\end{array}\\right) = \\left( \\begin{array}{rrr|r} 0 &  8 &  -4 &  0 \\\\ 1 &  -1 &  4 &  1 \\\\ -1 &  -5 &  2 &  0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Equation Operations***\n",
    "### One way to solve a linear system is by performing the following operations repeatedly, in some order:\n",
    "### - Multiply an equation by a nonzero number.\n",
    "### - Interchange two equations.\n",
    "### - Add a multiple of one equation to another equation.\n",
    "### Each of these operations are valid because they don't change the solution set.\n",
    "\n",
    "### ***Row operations***\n",
    "### The equation operations correspond to operations on the augmented matrix, called ***elementary row operations***:\n",
    "### - Multiply a row by a nonzero number.\n",
    "### - Interchange two rows.\n",
    "### - Add a multiple of one row to another row (while leaving the first row as it was).\n",
    "### We can do the following pairs of corresponding equation and row operations on the system and the augmented matrix:\n",
    "\n",
    "### 1. Multiply an equation by a nonzero number\n",
    "## $$ \\begin{array} {cc} \\text{1. Multiply an equation} & \\text{1. Multiply an equation} \\\\ \\text{by a nonzero number} & \\text{by a nonzero number} \\\\ \\, & \\, \\\\ \\begin{array} {lcr} {\\color{red}{(3)}} (8) y + {\\color{red}{(3)}} (-4) z & = & {\\color{red}{(3)}} (0) \\\\ x-y+4z & = & 1 \\\\ -x-5y+2z & = & 0 \\end{array} & {\\left( \\begin{array} {ccc|c} {\\color{red}{(3)}} (0) & {\\color{red}{(3)}} (8) & {\\color{red}{(3)}} (-4) & {\\color{red}{(3)}} (0) \\\\ 1 & -1 & 4 & 1 \\\\ -1 & -5 & 2 & 0 \\end{array} \\right)} \\\\ \\, & \\, \\\\ \\text{2. Interchange two equations} & \\text{2. Interchange two equations} \\\\ \\begin{array} {lcr} {\\color{red}{x-y+4z}} & {\\color{red}{=}} & {\\color{red}{1}} \\\\ {\\color{red}{8y-4z}} & {\\color{red}{=}} & {\\color{red}{0}} \\\\ -x-5y+2z & = & 0 \\end{array} & {\\left( \\begin{array} {ccc|c} {\\color{red}{1}} & {\\color{red}{-1}} & {\\color{red}{4}} & {\\color{red}{1}} \\\\ {\\color{red}{0}} & {\\color{red}{8}} & {\\color{red}{-4}} & {\\color{red}{0}} \\\\ -1 & -5 & 2 & 0 \\end{array} \\right)} \\\\ \\, & \\, \\\\ \\text{Add a multiple of one} & \\text{Add a multiple of one} \\\\  \\text{equation to another equation} & \\text{equation to another equation} \\\\ \\text{Adding 2 times the second equation} & \\text{Adding 2 times the second equation} \\\\  \\text{to the third one we get:} & \\text{to the third one we get:} \\\\ \\, & \\, \\\\ \\begin{array} {lcr} 8y-4z & = & 0 \\\\ x-y+4z & = & 1 \\\\ {\\color{red}{x-7y+10z}} & {\\color{red}{=}} & {\\color{red}{2}} \\end{array} & {\\left(\\begin{array} {ccc|c} 0 & 8 & -4 & 0 \\\\ 1 & -1 & 4 & 1 \\\\ {\\color{red}{1}} & {\\color{red}{-7}} & {\\color{red}{10}} & {\\color{red}{2}} \\end{array} \\right)} \\end{array} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b8569-1288-4157-b656-df74fe2911f4",
   "metadata": {},
   "source": [
    "## Gaussian elimination\n",
    "\n",
    "### ***Gaussian elimination*** is an algorithm that specifies a sequence of equation operations guaranteed to convert a linear system into one that we can solve easily. Usually this is described in terms of row operations on an augmented matrix. It converts this matrix into what is called ***row echelon form***. Here are the steps. Try reading them together with the example below.\n",
    "\n",
    "### 1. Find the left-most nonzero column, and the first nonzero entry in that column (read from the top down). Call this the first ***pivot***.\n",
    "### 2. If that entry is not already in the first row, interchange its row with the first row.\n",
    "### 3. Make all other entries of the column zero by adding suitable multiples of the first row to the others.\n",
    "### 4. At this point, the first row is done, so ignore it, and repeat the steps above for the remaining submatrix (with one fewer row and one fewer column). In each\n",
    "\n",
    "### With the algorithm, we can program a computer to solve large systems (100 equations with 100 unknowns).\n",
    "\n",
    "### ***Example 9.1***\n",
    "### Let us continue with the example from the previous page, and convert the augmented matrix to row echelon form using Gaussian elimination.\n",
    "## $$ \\begin{array} {rrr} 8y - 4z & = & 0 \\\\ x-y+4z & = & 1 \\\\ -x-5y+2z & = & 0 \\end{array} $$\n",
    "\n",
    "## $$ \\left( \\begin{array} {c|c} \\bf{A} & \\bf{b} \\end{array}\\right) = \\left( \\begin{array}{rrr|r} 0 &  8 &  -4 &  0 \\\\ 1 &  -1 &  4 &  1 \\\\ -1 &  -5 &  2 &  0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 1.*** The leftmost nonzero column is the first one, and its first nonzero entry is the ${\\color{red}{1}}$:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{orange}{0}} &  8 &  -4 &  0 \\\\ {\\color{red}{1}} &  -1 &  4 &  1 \\\\ {\\color{orange}{-1}} &  -5 &  2 &  0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 2.*** The ${\\color{red}{1}}$ is not in the rist row, so interchange its row with the first row:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{red}{1}} &  -1 &  4 &  1 \\\\ {\\color{orange}{0}} &  8 &  -4 &  0 \\\\ {\\color{orange}{-1}} &  -5 &  2 &  0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 3.*** To make all other entries of the column zero, we need to add $1$ times the first row to the last row (the second row is OK already):\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{red}{1}} &  -1 &  4 &  1 \\\\ {\\color{orange}{0}} &  8 &  -4 &  0 \\\\ {\\color{orange}{0}} &  -6 &  6 &  1 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 4.*** Because entries below the pivot are all zero, the first row (in gray) is done. Start over with the submatrix that remains beneath th first row:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{gray}{1}} &  {\\color{gray}{-1}} &  {\\color{gray}{4}} &  {\\color{gray}{1}} \\\\ 0 &  8 &  -4 &  0 \\\\ 0 &  -6 &  6 &  1 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step1.*** The leftmost nonzero column is now the second column, and its first nonzero entry is the ${\\color{red}{8}}$:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{gray}{1}} &  {\\color{gray}{-1}} &  {\\color{gray}{4}} &  {\\color{gray}{1}} \\\\ 0 &  {\\color{red}{8}} &  -4 &  0 \\\\ 0 &  {\\color{orange}{-6}} &  6 &  1 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 2.*** The first nonzero entry is ${\\color{red}{8}}$, which is already in the first row of the submatrix (we are ignoring the first row of the whole matrix), so no interchange is necessary.\n",
    "\n",
    "### ***Step 3.*** To make all other entries below the pivot of the column zero, add $6/8$ times the (new) first row to the (new) second row:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{gray}{1}} &  {\\color{gray}{-1}} &  {\\color{gray}{4}} &  {\\color{gray}{1}} \\\\ 0 &  {\\color{red}{8}} &  -4 &  0 \\\\ 0 &  {\\color{orange}{0}} &  3 &  1 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 4.*** Now the first and secnd row of the original matrix are done (both now in gray). Start over with the submatrix beneath them:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{gray}{1}} &  {\\color{gray}{-1}} &  {\\color{gray}{4}} &  {\\color{gray}{1}} \\\\ {\\color{gray}{0}} &  {\\color{gray}{8}} &  {\\color{gray}{-4}} &  {\\color{gray}{0}} \\\\ 0 &  0 &  3 &  1 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 1.*** The lefmost nonzero column is now the third column, and its first nonzero entry is the ${\\color{red}{3}}$ at the bottom:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{gray}{1}} &  {\\color{gray}{-1}} &  {\\color{gray}{4}} &  {\\color{gray}{1}} \\\\ {\\color{gray}{0}} &  {\\color{gray}{8}} &  {\\color{gray}{-4}} &  {\\color{gray}{0}} \\\\ 0 &  0 &  {\\color{red}{3}} &  1 \\end{array} \\right) $$\n",
    "\n",
    "### There are no columns below this column, so we are done.\n",
    "\n",
    "### The matrix is now in ***row echelon*** form:\n",
    "### ***Step 1.*** The lefmost nonzero column is now the third column, and its first nonzero entry is the ${\\color{red}{3}}$ at the bottom:\n",
    "## $$ \\left( \\begin{array}{rrr|r} {\\color{red}{1}} &  -1 &  4 &  1 \\\\ 0 &  {\\color{red}{8}} &  -4 &  0 \\\\ 0 &  0 &  {\\color{red}{3}} &  1 \\end{array} \\right) $$\n",
    "\n",
    "### The first nonzero entry in each row is the ***pivot***.\n",
    "\n",
    "### ***Definition 9.2***\n",
    "### A matrix is in ***row echelon form*** if it satisfies the following conditions:\n",
    "### 1. All the zero rows (if any) are grouped at the bottom of the matrix.\n",
    "### 2. The first nonzero entry in a nonzero row, which we call the ***pivot***, lies farther to the right than the pivots of higher rows.\n",
    "### 3. All entries in the column below a pivot entry are zero.\n",
    "\n",
    "### ***Warning***\n",
    "### Some books require also that each pivot be a $1$. We are not going to require this for row echelon form, but we will require it for ***reduced*** row echelon form later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83d6d6-5de0-4bae-9523-33c47bc59bde",
   "metadata": {},
   "source": [
    "### ***Example 9.3***\n",
    "### The following matrices are all in row echelon form. The pivots are highlighted in ${\\color{red}{\\text{red}}}$.\n",
    "\n",
    "## $$ \\begin{pmatrix} {\\color{red}{1}} & 4 & 5 \\\\ 0 & {\\color{red}{3}} & 0 \\\\ 0 & 0 & {\\color{red}{8}} \\end{pmatrix} \\quad \\begin{pmatrix} {\\color{red}{1}} & 4 & 5 \\\\ 0 & {\\color{red}{3}} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\quad \\begin{pmatrix} {\\color{red}{4}} & -1 & 0 & 0 \\\\ 0 & {\\color{red}{3}} & 2 & 1 \\\\ 0 & 0 & 0 & {\\color{red}{4}} \\end{pmatrix} \\quad \\begin{pmatrix} {\\color{red}{1}} & 3 & 1 \\\\ 0 & 0 & {\\color{red}{4}} \\\\ 0 & 0 & 0  \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} $$\n",
    "\n",
    "### ***Nonexamples***\n",
    "### The following matrices are not in row echelon form.\n",
    "### 1. THe following matrix has a zero row (in orange) that is above a nonzero row.\n",
    "## $$ \\begin{pmatrix} 1 & 4 & 5 \\\\ {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{0}} \\\\ 0 & 3 & 0 \\end{pmatrix} $$\n",
    "### 2. The following matrix is not in row echelon form because the pivot in the third row is to the left of the pivot in the second row (both in orange):\n",
    "## $$ \\begin{pmatrix} 4 & -1 & 0 & 0 \\\\ 0 & 0 & {\\color{orange}{2}} & 1 \\\\ 0 & {\\color{orange}{1}} & 0 & 1 \\end{pmatrix} $$\n",
    "### 3. The following matrix is not in row echelon form because the entries below the ***pivot*** in the second row are not all zero (orange):\n",
    "## $$ \\begin{pmatrix} 1 & 3 & 1 \\\\ 0 & 0 & {\\color{red}{4}} \\\\ 0 & 0 & 0 \\\\ 0 & 0 & {\\color{orange}{2}} \\\\ 0 & 0 & 0 \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136157b7-b7d7-4662-a480-0cd981fd5daa",
   "metadata": {},
   "source": [
    "### ***Definition 9.4***\n",
    "### A row echelon form of a matrix $\\bf{A}$ is any matrix in row echelon form obtained from $\\bf{A}$ by a sequence of row operations.\n",
    "\n",
    "### ***Note***\n",
    "### Gaussian elimination is one algorithm for obtaining a row echelon form of a matrix. However, there are other sequences of row operations that will lead to different row echelon forms. However, all of these row echelon forms have the same solution set as the original system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2effa60d-4f44-408f-ac9b-d670895165a0",
   "metadata": {},
   "source": [
    "## Back-substitution\n",
    "\n",
    "### ***Key point of row echelon form***: Matrices in row echelon form correspond to systems that are ready to be solved immediately by ***back-substitution***. To perform back-substitution, you solve for each variable in reverse order (from bottom row to top row). (On the next page, we will see that you must introduce a parameter for each variable that can not be directly expressed in terms of later variables, and substitute values into earlier equations once they are known.)\n",
    "\n",
    "### ***Example problem***\n",
    "### The augmented matrix in row echelon form\n",
    "## $$ \\left( \\begin{array} {rrr|r} 1 & -1 & 4 1 \\\\ 0 & 8 & -4 & 0 \\\\ 0 & 0 & 3 & 1 \\end{array} \\right) $$\n",
    "### describes a system of equations\n",
    "## $$ \\begin{array} {rcr} x-y+4z & = & 1 \\\\ 8y-4z & = & 0 \\\\ 3z & = & 1 \\end{array} $$\n",
    "### Find the general solution to the system.\n",
    "\n",
    "### ***Solution***\n",
    "### Solve the last equation first to get\n",
    "## $$ z = \\frac{1}{3} $$\n",
    "### Substitute this into the second to last equation to get:\n",
    "## $$ \\begin{array} {rcc} 8y - 4 (\\frac{1}{3}) & = & 0 \\\\ y & = & \\frac{1}{6} \\end{array} $$\n",
    "### Now substitute both values into the first equation to get\n",
    "## $$ \\begin{array} {rcl} x - \\frac{1}{6}+\\frac{4}{3} & = & 1 \\\\ x & = & 1+\\frac{1}{6}-\\frac{4}{3} = -\\frac{1}{6} \\end{array} $$\n",
    "### Conclusion: The general solution written as a column vector is:\n",
    "## $$ \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{6} \\\\ \\frac{1}{6} \\\\ \\frac{1}{3} \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a726459-d096-4cf0-9eb8-3c6e9d2f19db",
   "metadata": {},
   "source": [
    "## Complicated example with free variables\n",
    "\n",
    "### ***Goal***: After writing the system as an augmented matrix, apply Gaussian elimination to put the augmented matrix into row echelon form, and then use back substitution to solve the system.\n",
    "\n",
    "## $$ \\begin{array} {rcl} 6z+2u-4v-8w & = & 8 \\\\ 3z+u-2v-4w & = & 4 \\\\ 2x-3y+z+4u-7v+w & = & 2 \\\\ 6x-9y+11u-19v+3w & = & 0 \\end{array} $$\n",
    "\n",
    "### ***Solution***\n",
    "### Start by writing the system as an augmented matrix.\n",
    "## $$ \\left( \\begin{array} {cccccc|c} 0 & 0 & 6 & 2 & -4 & -8 & 8 \\\\ 0 & 0 & 3 & 1 & -2 & -4 & 4 \\\\ 2 & -3 & 1 & 4 & -7 & 1 & 2 \\\\ 6 & -9 & 0 & 11 & -19 & 3 & 0 \\end{array} \\right) $$\n",
    "\n",
    "### Next we apply the steps of Gaussian elimination. \n",
    "\n",
    "### ***Step 1.*** The leftmost nonzero column is the first one, and its first nonzero entry is the ${\\color{red}{2}}$:\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{orange}{0}} & 0 & 6 & 2 & -4 & -8 & 8 \\\\ {\\color{orange}{0}} & 0 & 3 & 1 & -2 & -4 & 4 \\\\ {\\color{red}{2}} & -3 & 1 & 4 & -7 & 1 & 2 \\\\ {\\color{orange}{6}} & -9 & 0 & 11 & -19 & 3 & 0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 2.*** The ${\\color{red}{2}}$ is not in the first row, so interchange its row with the first row:\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{red}{2}} & -3 & 1 & 4 & -7 & 1 & 2 \\\\ {\\color{orange}{0}} & 0 & 3 & 1 & -2 & -4 & 4 \\\\ {\\color{orange}{0}} & 0 & 6 & 2 & -4 & -8 & 8 \\\\ {\\color{orange}{6}} & -9 & 0 & 11 & -19 & 3 & 0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 3.*** To make all other entries of the column zero, we need to subtract $3$ times the first row from the last row (the second and third rows are OK already):\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{red}{2}} & -3 & 1 & 4 & -7 & 1 & 2 \\\\ {\\color{orange}{0}} & 0 & 3 & 1 & -2 & -4 & 4 \\\\ {\\color{orange}{0}} & 0 & 6 & 2 & -4 & -8 & 8 \\\\ {\\color{orange}{0}} & 0 & -3 & -1 & 2 & 0 & -6 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 4.*** Because entries below the pivot are all zero, the first row (in gray) is done. Start over with the submatrix that remains beneath the first row:\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{gray}{2}} & {\\color{gray}{-3}} & {\\color{gray}{1}} & {\\color{gray}{4}} & {\\color{gray}{-7}} & {\\color{gray}{1}} & {\\color{gray}{2}} \\\\ 0 & 0 & 3 & 1 & -2 & -4 & 4 \\\\ 0 & 0 & 6 & 2 & -4 & -8 & 8 \\\\ 0 & 0 & -3 & -1 & 2 & 0 & -6 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 1.*** The leftmost nonzero column is now the third column, and its first nonzero entry is the ${\\color{red}{3}}$:\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{gray}{2}} & {\\color{gray}{-3}} & {\\color{gray}{1}} & {\\color{gray}{4}} & {\\color{gray}{-7}} & {\\color{gray}{1}} & {\\color{gray}{2}} \\\\ 0 & 0 & {\\color{red}{3}} & 1 & -2 & -4 & 4 \\\\ 0 & 0 & {\\color{orange}{6}} & 2 & -4 & -8 & 8 \\\\ 0 & 0 & {\\color{orange}{-3}} & -1 & 2 & 0 & -6 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 2.*** The first nonzero entry is ${\\color{red}{3}}$, which is already in the first row of the submatrix (we are ignoring the first row of the whole matrix), so no interchange is necessary.\n",
    "\n",
    "### ***Step 3.*** To make all other entries below the pivot of the column zero, subtract $2$ times the (new) first row to the (new) second row, and add the (new) first row to the (new) third row:\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{gray}{2}} & {\\color{gray}{-3}} & {\\color{gray}{1}} & {\\color{gray}{4}} & {\\color{gray}{-7}} & {\\color{gray}{1}} & {\\color{gray}{2}} \\\\ 0 & 0 & {\\color{red}{3}} & 1 & -2 & -4 & 4 \\\\ 0 & 0 & {\\color{orange}{0}} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & {\\color{orange}{0}} & 0 & 0 & -4 & -2 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 4.*** Now the first and second row of the original matrix are done (both now in gray). Start over with the submatrix beneath them:\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{gray}{2}} & {\\color{gray}{-3}} & {\\color{gray}{1}} & {\\color{gray}{4}} & {\\color{gray}{-7}} & {\\color{gray}{1}} & {\\color{gray}{2}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{3}} & {\\color{gray}{1}} & {\\color{gray}{-2}} & {\\color{gray}{-4}} & {\\color{gray}{4}} \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & -4 & -2 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 2.*** The ${\\color{red}{-4}}$ is not in the first row of the submatrix, so interchange its row with the first row of the submatrix:\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{gray}{2}} & {\\color{gray}{-3}} & {\\color{gray}{1}} & {\\color{gray}{4}} & {\\color{gray}{-7}} & {\\color{gray}{1}} & {\\color{gray}{2}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{3}} & {\\color{gray}{1}} & {\\color{gray}{-2}} & {\\color{gray}{-4}} & {\\color{gray}{4}} \\\\ 0 & 0 & 0 & 0 & 0 & {\\color{red}{-4}} & -2 \\\\ 0 & 0 & 0 & 0 & 0 & {\\color{orange}{0}} & 0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Step 3.*** The other entry in this column of the submatrix is already $0$, so this step is not necessary.\n",
    "\n",
    "### The matrix is now in row ***echelon form***. The first nonzero entry in each column is the ***pivot***.\n",
    "## $$ \\left( \\begin{array} {cccccc|c} {\\color{red}{2}} & -3 & 1 & 4 & -7 & 1 & 2 \\\\ 0 & 0 & {\\color{red}{3}} & 1 & -2 & -4 & 4 \\\\ 0 & 0 & 0 & 0 & 0 & {\\color{red}{-4}} & -2 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{array} \\right) $$\n",
    "\n",
    "### This is augmented matrix for the system\n",
    "## $$ \\begin{array} {rcl} 2x-3y+z+4u-7v+w & = & 2 \\\\ 3z+u-2v-4w & = & 4 \\\\ -4w & = & -2 \\end{array} $$\n",
    "\n",
    "### Suppose that a matrix is in row echelon form. \n",
    "### Then any column that contains a pivot is called a ***pivot column***.\n",
    "### A variable whose corresponding column is a pivot column is called a ***dependent variable*** or ***pivot variable***. \n",
    "### The other variables are called ***free variables***. (The augmented column does not correspond to any variable.)\n",
    "\n",
    "### In the problem above, ${\\color{red}{x}}$, ${\\color{red}{z}}$, ${\\color{red}{w}}$ are dependent variables, and ${\\color{orange}{y}}$, ${\\color{orange}{u}}$, ${\\color{orange}{v}}$ are free variables.\n",
    "\n",
    "### ***Back substitution***\n",
    "\n",
    "### Now we are ready to back-substitute. Solve for $w$ in\n",
    "## $$ -4{\\color{red}{w}} = -2 $$\n",
    "### to get\n",
    "## $$ {\\color{red}{w}} = \\frac{1}{2} $$\n",
    "### There is no equation for ${\\color{orange}{v}}$ in terms of the later variable ${\\color{red}{w}}$, so ${\\color{orange}{v}}$ can be any number.\n",
    "### Set\n",
    "## $$ {\\color{orange}{v}} = c_1 \\quad \\text{for a parameter }\\, c_1 $$\n",
    "### There is no equation for ${\\color{orange}{u}}$ in terms ${\\color{orange}{v}}$ and ${\\color{red}{w}}$, so set\n",
    "## $$ {\\color{orange}{u}} = c_2 \\quad \\text{for a parameter}\\, c_2 $$\n",
    "### Solving the second equation for ${\\color{red}{z}}$ we find\n",
    "## $$ \\begin{array} {rcl} 3{\\color{red}{z}} + c_2 - 2c_1-4\\frac{1}{2} & = & 4 \\\\ {\\color{red}{z}} & = & 2 - \\frac{1}{3}c_2 + \\frac{2}{3}c_1 \\end{array} $$\n",
    "### where $c_1$ and $c_2$ are free parameters.\n",
    "### There is no equation for ${\\color{orange}{y}}$ in terms of the later variables ${\\color{red}{z}}$, ${\\color{orange}{u}}$, ${\\color{orange}{v}}$ and ${\\color{red}{w}}$, so set\n",
    "## $$ {\\color{red}{y}} = c_3 \\quad \\, \\text{for a parameter}\\,c_3 $$\n",
    "### Solvng for the first equation for ${\\color{red}{x}}$ we find\n",
    "## $$ \\begin{array} {rcl} 2{\\color{red}{x}} - 3c_3+{\\color{red}{z}}+4c_2-7c_1+{\\color{red}{w}} & = & 2 \\\\ 2{\\color{red}{x}} - 3c_3+(2-\\frac{1}{3}c_2+\\frac{2}{3}c_1)+4c_2-7c_1+\\frac{1}{2} & = & 2 \\\\ 2{\\color{red}{x}}-3c_3+\\frac{11}{3}c_2-\\frac{19}{3}c_1 & = & -\\frac{1}{2} \\\\ {\\color{red}{x}} & = & -\\frac{1}{4} + \\frac{19}{6}c_1-\\frac{11}{6}c_2+\\frac{3}{2}c_3 \\end{array} $$\n",
    "### where $c_1$, $c_2$ and $c_3$ are free parameters\n",
    "### THerefore the general solution is given by\n",
    "## $$ \\begin{pmatrix} {\\color{red}{x}} \\\\ {\\color{orange}{y}} \\\\ {\\color{red}{z}} \\\\ {\\color{orange}{u}} \\\\ {\\color{orange}{v}} \\\\ {\\color{red}{w}} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{4} + \\frac{19}{6}c_1-\\frac{11}{6}c_2+\\frac{3}{2}c_3 \\\\ c_3 \\\\ 2+\\frac{2}{3}c_1-\\frac{1}{3}c_2 \\\\ c_2 \\\\ c_1 \\\\ \\frac{1}{2}  \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{4} \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\\\ \\frac{1}{2} \\end{pmatrix} + c_1 \\begin{pmatrix} \\frac{19}{6} \\\\ 0 \\\\ \\frac{2}{3} \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} + c_2 \\begin{pmatrix} -\\frac{11}{6} \\\\ 0 \\\\ -\\frac{1}{3} \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + c_3 \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\n",
    "### Note that the three parameters correspond to the three free variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc27814-8ede-4ad2-89f4-e3a16e5be5c4",
   "metadata": {},
   "source": [
    "## Worked example 1\n",
    "\n",
    "### ***Example 12.1***\n",
    "### Solve the linear system \n",
    "## $$ 4x + 3y + z = 5 $$\n",
    "\n",
    "### ***Solution***\n",
    "### This linear system describes a plane in $\\mathbb{R}^3$. We can represent this equation as the matrix equation:\n",
    "## $$ \\begin{pmatrix} 4 & 3 & 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = 5 $$\n",
    "\n",
    "### To find the general solution we notice that the matrix $\\begin{pmatrix} {\\color{red}{4}} & 3 & 1 \\end{pmatrix} $ is already is row echelon form. It has one pivot, and $2$ free columns. The pivot variable or dependent variable is ${\\color{red}{x}}$. The free variables or independent variables are ${\\color{orange}{y}}$ and ${\\color{orange}{z}}$.\n",
    "\n",
    "### Set the free variables equal to parameters since they cannot be determined from the equation:\n",
    "## $$ \\begin{array} {rcl} {\\color{orange}{y}} & = & c_1 \\\\ {\\color{orange}{z}} & = & c_2 \\end{array} $$\n",
    "\n",
    "### Then solve for ${\\color{red}{x}}$ using back substitution:\n",
    "## $$ \\begin{array} {rcl} 4{\\color{red}{x}} + 3{\\color{orange}{y}}+{\\color{orange}{z}} & = & 5 \\\\ 4{\\color{red}{x}} + 3c_1 + c_2 & = & 5 \\\\ {\\color{red}{x}} & = & \\frac{5-3c_1-c_2}{4} \\end{array} $$\n",
    "\n",
    "### Putting everything together we get\n",
    "\n",
    "## $$ \\begin{pmatrix} {\\color{red}{x}} \\\\ {\\color{orange}{y}} \\\\ {\\color{orange}{z}} \\end{pmatrix} = \\begin{pmatrix} \\frac{5-3c_1-c_2}{4} \\\\ c_1 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{4} \\\\ 0 \\\\ 0 \\end{pmatrix} + c_1 \\begin{pmatrix} -\\frac{3}{4} \\\\ 1 \\\\ 0 \\end{pmatrix} + c_2 \\begin{pmatrix} -\\frac{1}{4} \\\\ 0 \\\\ 1 \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d7ef8-49ae-41d0-b902-45672294d887",
   "metadata": {},
   "source": [
    "## Worked example 2\n",
    "\n",
    "### ***Example 12.2***\n",
    "### Solve the linear system\n",
    "## $$ \\begin{array} {rcl} x+y+z+w & = & 4 \\\\ x + 2y + 3z + 4w & = & 7 \\\\ y + 2z + 3w & = & 3 \\end{array} $$\n",
    "\n",
    "### ***Solution***\n",
    "### First, put the system of linear equations into matrix form:\n",
    "## $$ \\begin{pmatrix} 1 & 1 & 1 & 1 \\\\ 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 3 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\\\ w \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 7 \\\\ 3 \\end{pmatrix} $$\n",
    "\n",
    "### Next we form the ugmented matrix and put it into row echelon form:\n",
    "## $$ \\left( \\begin{array} {cccc|c} 1 & 1 & 1 & 1 & 4 \\\\ 1 & 2 & 3 & 4 & 7 \\\\ 0 & 1 & 2 & 3 & 3 \\end{array} \\right) \\to \\left( \\begin{array} {cccc|c} 1 & 1 & 1 & 1 & 4 \\\\ 0 & 1 & 2 & 3 & 3 \\\\ 0 & 1 & 2 & 3 & 3 \\end{array} \\right) \\to \\left( \\begin{array} {cccc|c} {\\color{red}{1}} & 1 & 1 & 1 & 4 \\\\ 0 & {\\color{red}{1}} & 2 & 3 & 3 \\\\ 0 & 0 & 0 & 0 & 0 \\end{array} \\right)$$\n",
    "\n",
    "### The row echelon form of the augmented matrix has two pivots in orange. Therefore it has two free columns (not counting the augmented column).\n",
    "\n",
    "### The ***dependent*** or ***pivot*** variables are ${\\color{red}{x}}$ and ${\\color{red}{y}}$. The ***independent*** or ***free*** variables are ${\\color{orange}{z}}$ and ${\\color{orange}{w}}$.\n",
    "\n",
    "### Set the free variables equal to new parameters,\n",
    "## $$ \\begin{array} {rcl} {\\color{orange}{z}} & = & c_1 \\\\ {\\color{orange}{w}} & = & c_2 \\end{array} $$\n",
    "\n",
    "### The second to last row in the augmented matrix is equivalent to the equation\n",
    "## $$ {\\color{red}{y}} + 2{\\color{orange}{z}}+3{\\color{orange}{w}} = 3 $$\n",
    "\n",
    "### Use back substitution to solve for ${\\color{red}{y}}$ in terms of the parameters.\n",
    "## $$ \\begin{array} {rcl} {\\color{red}{y}} + 2c_1 + 3c_2 & = & 3 \\\\ {\\color{red}{y}} & = & 3 - 2c_1-3c_2 \\end{array} $$\n",
    "\n",
    "### The first row in the augmented matrix is equivalent to the equation\n",
    "## $$ {\\color{red}{x}} + {\\color{red}{y}} + {\\color{orange}{z}} + {\\color{orange}{w}} = 4 $$\n",
    "\n",
    "### Use back substitutionto solve for ${\\color{red}{x}}$:\n",
    "## $$ \\begin{array} {rcl} {\\color{red}{x}}+(3-2c_1-3c_2)+c_1+c_2 & = & 4 \\\\ {\\color{red}{x}}+3-c_1-2c_2 & = & 4 \\\\{\\color{red}{x}} & = & 1+c_1+2c_2 \\end{array} $$\n",
    "\n",
    "### Writing the solution in vector form we find that the general solution is\n",
    "## $$ \\begin{pmatrix} {\\color{red}{x}} \\\\ {\\color{red}{y}} \\\\ {\\color{orange}{z}} \\\\ {\\color{orange}{w}} \\end{pmatrix} = \\begin{pmatrix} 1 + c_1+2c_2 \\\\ 3-2c_1-3c_2 \\\\ c_1 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\\\ 0 \\end{pmatrix} + c_1 \\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\\\ 0 \\end{pmatrix} + c_2 \\begin{pmatrix} 2 \\\\ -3 \\\\ 0 \\\\ 1\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef75fcb-58b2-4d97-b272-72d6e2321db5",
   "metadata": {},
   "source": [
    "## Gaussâ€“Jordan elimination\n",
    "### Jordan recognized the fact that Gaussian elimination can be continued to algorithmically perform the back substitution step as well. The result of this algorithm is called the ***reduced row echelon form***.\n",
    "\n",
    "### ***Definition 13.1***\n",
    "### A matrix is in ***reduced row echelon form (rref)*** if it satisfies all of the following conditions:\n",
    "### 1. It is in row echelon form\n",
    "### 2. Each pivot is a $1$\n",
    "### 3. In each pivot column, all the entries are $0$ except for the pivot itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec0848-7d17-4d1a-957d-1b16b332e958",
   "metadata": {},
   "source": [
    "## Gaussâ€“Jordan elimination algorithm\n",
    "\n",
    "### ***Gaussâ€“Jordan elimination*** is the name of the algorithm for converting any matrix into reduced row echelon form by performing row operations. Here are the steps:\n",
    "### 1. Use Gaussian elimination to convert the matrix to row echelon form.\n",
    "### 2. Divide the last nonzero row by its pivot, to make the pivot $1$.\n",
    "### 3. Make all entries in that pivot's column $0$ by adding suitable multiples of the pivot's row to the rows above.\n",
    "### 4. At this point, the row in question (and all rows below it) are done. Ignore them, and go back to Step 2, but now with the remaining submatrix, above the row just completed.\n",
    "\n",
    "### Eventually the whole matrix will be in reduced row echelon form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d89acb-9d0e-481a-b7b5-27a1cb18a6c6",
   "metadata": {},
   "source": [
    "### ***Problem 13.2***\n",
    "### Convert the $4 \\times 7$ matrix\n",
    "## $$ \\begin{pmatrix} 2 & -3 & 1 & 4 & -7 & 1 & 2 \\\\ 0 & 0 & 3 & 1 & -2 & -4 & 4 \\\\ 0 & 0 & 0 & 0 & 0 & -4 & -2 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{pmatrix} $$\n",
    "### to reduced row echelon form\n",
    "\n",
    "### ***Solution***:\n",
    "### ***Step 1.*** The matrix is already in row echelon form.\n",
    "### ***Step 2.*** The last nonzero row is the third row, and its pivot is the ${\\color{red}{-4}}$, so divide the third row by ${\\color{red}{-4}}$:\n",
    "## $$ \\begin{pmatrix} 2 & -3 & 1 & 4 & -7 & 1 & 2 \\\\ 0 & 0 & 3 & 1 & -2 & -4 & 4 \\\\ 0 & 0 & 0 & 0 & 0 & {\\color{red}{1}} & {\\color{orange}{\\frac{1}{2}}} \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{pmatrix} $$\n",
    "### ***Step 3.*** To make all other entries of that pivot's column $0$, add $-1$ times the third row to the first row, and add $4$ times the third row to the second row:\n",
    "## $$ \\begin{pmatrix} 2 & -3 & 1 & 4 & -7 & {\\color{orange}{0}} & \\frac{3}{2} \\\\ 0 & 0 & 3 & 1 & -2 & {\\color{orange}{0}} & 6 \\\\ 0 & 0 & 0 & 0 & 0 & {\\color{red}{1}} & \\frac{1}{2} \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 \\end{pmatrix} $$\n",
    "\n",
    "### ***Step 4.*** Now the last two rows are done:\n",
    "## $$ \\begin{pmatrix} 2 & -3 & 1 & 4 & -7 & 0 & \\frac{3}{2} \\\\ 0 & 0 & 3 & 1 & -2 & 0 & 6 \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{1}} & {\\color{gray}{\\frac{1}{2}}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} &  {\\color{gray}{0}}& {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} \\end{pmatrix} $$\n",
    "\n",
    "### Go back to Step 2, but with the $2 \\times 7$ submatrix above them.\n",
    "\n",
    "### ***Step 2.*** The last nonzero row of the new matrix (ignoring the bottom two rows of the original matrix) is the second row, and it's pivot is the ${\\color{red}{3}}$, so we divide the second row by ${\\color{red}{3}}$:\n",
    "## $$ \\begin{pmatrix} 2 & -3 & 1 & 4 & -7 & 0 & \\frac{3}{2} \\\\ {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{red}{1}} & {\\color{orange}{\\frac{1}{3}}} & {\\color{orange}{-\\frac{2}{3}}} & {\\color{orange}{0}} & {\\color{orange}{2}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{1}} & {\\color{gray}{\\frac{1}{2}}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} &  {\\color{gray}{0}}& {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} \\end{pmatrix} $$\n",
    "\n",
    "### ***Step 3.*** To make the other entries of that pivot's column $0$, add $-1$ times the second row to the first row:\n",
    "## $$ \\begin{pmatrix} 2 & -3 & {\\color{orange}{0}} & \\frac{11}{3} & -\\frac{19}{3} & 0 & -\\frac{1}{2} \\\\ 0 & 0 & {\\color{red}{1}} & \\frac{1}{3} & -\\frac{2}{3} & 0 & 2 \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{1}} & {\\color{gray}{\\frac{1}{2}}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} &  {\\color{gray}{0}}& {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} \\end{pmatrix} $$\n",
    "\n",
    "### ***Step 4.*** Now the last three rows are done:\n",
    "## $$ \\begin{pmatrix} 2 & -3 & 0 & \\frac{11}{3} & -\\frac{19}{3} & 0 & -\\frac{1}{2} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{1}} & {\\color{gray}{\\frac{1}{3}}} & {\\color{gray}{-\\frac{2}{3}}} & {\\color{gray}{0}} & {\\color{gray}{2}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{1}} & {\\color{gray}{\\frac{1}{2}}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} &  {\\color{gray}{0}}& {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} \\end{pmatrix} $$\n",
    "\n",
    "### Go back to Step 2, but with the $1 \\times 7$ submatrix above them.\n",
    "\n",
    "### ***Step 2.*** The last nonzero row of new matrix is the only remaining row (the first row), and it's pivot is the initial ${\\color{red}{2}}$, so we divide the first row by ${\\color{red}{2}}$:\n",
    "## $$ \\begin{pmatrix} {\\color{red}{1}} & {\\color{orange}{-\\frac{3}{2}}} & {\\color{orange}{0}} & {\\color{orange}{\\frac{11}{6}}} & {\\color{orange}{-\\frac{19}{6}}} & {\\color{orange}{0}} & {\\color{orange}{-\\frac{1}{4}}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{1}} & {\\color{gray}{\\frac{1}{3}}} & {\\color{gray}{-\\frac{2}{3}}} & {\\color{gray}{0}} & {\\color{gray}{2}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{1}} & {\\color{gray}{\\frac{1}{2}}} \\\\ {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} &  {\\color{gray}{0}}& {\\color{gray}{0}} & {\\color{gray}{0}} & {\\color{gray}{0}} \\end{pmatrix} $$\n",
    "\n",
    "### The matrix is now in reduced row echelon form.\n",
    "\n",
    "### ***Remark 13.3***\n",
    "### Performing row operations on $\\bf{A}$ in a different order than specified by Gaussian elimination and Gauss-Jordan elimination can lead to different row echelon forms. But it turns out that row operations leading to reduced row echelon form always give the same result, a matrix that we will write as $\\operatorname{rref}(\\bf{A})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9749b7-989c-45b0-b2d8-8deab20667e7",
   "metadata": {},
   "source": [
    "## Balancing a chemical reaction\n",
    "\n",
    "### Let's consider the problem of balancing a chemical reaction. \n",
    "### Suppose that we need to find the smallest positive integers $a$, $b$, $c$, and $d$ that balance the reaction\n",
    "## $$ a\\mathrm{N}\\mathrm{O}_2+b\\mathrm{H}_2\\mathrm{O} \\longrightarrow c\\mathrm{H} \\mathrm{N} \\mathrm{O}_2 + d \\mathrm{H} \\mathrm{N} \\mathrm{O}_3 $$\n",
    "\n",
    "### The constraint that the number of nitrogen atoms on the left and right hand sides of the reaction must be equal says that\n",
    "## $$ a = c + d $$\n",
    "\n",
    "### which can be rewritten as $a-c-d = 0$. Similarly, there is a constrint on the number of oxygen and hydrogen atoms on both sides of the equation. These equations constitute a linear system\n",
    "## $$ \\begin{array} {rclr} a - c - d & = & 0 & \\text{(nitrogen)} \\\\ 2a+b-2c-3d & = & 0 & \\text{(oxygen)} \\\\ 2b - c-d & = & 0 & \\text{(hydrogen)} \\end{array} $$\n",
    "\n",
    "### This linear system in matrix form $\\bf{A}\\bf{x}=\\bf{b}$ is\n",
    "## $$ \\underset{\\bf{A}}{ \\begin{pmatrix} 1 & 0 & -1 & -1 \\\\ 2 & 1 & -2 & -3 \\\\ 0 & 2 & -1 & -1 \\end{pmatrix} } \\underset{\\bf{x}}{ \\begin{pmatrix} a \\\\ b \\\\ c \\\\ d \\end{pmatrix} }  = \\underset{\\bf{b}}{ \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} }  $$\n",
    "### which can be represented by the augmented matrix.\n",
    "## $$ \\left( \\begin{array} {cccc|c} 1 & 0 & -1 & -1 & 0 \\\\ 2 & 1 & -2 & -3 & 0 \\\\ 0 & 2 & -1 & -1 & 0 \\end{array} \\right) $$\n",
    "\n",
    "### ***Definition 2.1***\n",
    "### A linear system is ***homogenous*** is the right hand sides (the constants in the vector $\\bf{b}$) are all zero, and ***inhomogeneous*** otherwise. So a linear system is homogeneous if and only if the zero vector is a solution.\n",
    "\n",
    "### To solve a homogeneous system, we use elimination to put the augmented matrix in row echelon form. The leftmost pivot in each subsequent column is denoted in blue as we move through the steps of the algorithm. (The augmented column is all zeros, so it contains no extra information. It would be OK to leave this column off, but we will keep it in order to have a uniform approach for both homogeneous and inhomogeneous systems.)\n",
    "\n",
    "## $$ \\bf{A} = \\left( \\begin{array} {cccc|c} 1 & 0 & -1 & -1 & 0 \\\\ 2 & 1 & -2 & -3 & 0 \\\\ 0 & 2 & -1 & -1 & 0 \\end{array} \\right) \\longrightarrow \\left( \\begin{array} {cccc|c} {\\color{red}{1}} & 0 & -1 & -1 & 0 \\\\ 0 & {\\color{red}{1}} & 0 & -1 & 0 \\\\ 0 & 2 & -1 & -1 & 0 \\end{array} \\right) \\longrightarrow \\left( \\begin{array} {cccc|c} {\\color{red}{1}} & 0 & -1 & -1 & 0 \\\\ 0 & {\\color{red}{1}} & 0 & -1 & 0 \\\\ 0 & 0 & {\\color{red}{-1}} & 1 & 0 \\end{array} \\right) $$\n",
    "\n",
    "### Let $\\bf{U}$ be the row echelon form of $\\bf{A}$ that we just found. Then solving the system $\\bf{U} \\bf{x} = 0$ is equivalent to solving $\\bf{A} \\bf{x} = 0$. The system $\\bf{U} \\bf{x} = 0$ written as a system of equations is\n",
    "## $$ \\begin{array} {rcl} a-c-d & = & 0 \\\\ b-d & = & 0 \\\\ -c+d & = & 0 \\end{array} $$\n",
    "\n",
    "### Recall that in back-substitution we solve for the variables in reverse order. If a variable corresponds to a pivot column, then some equation expresses it in terms of later variables. Recall that the variables, corresponding to non-pivot columns, are called free variables. And each free variable requires a new parameter. In this case, our free variable is $d$; its value can be any real number. So we rename this variable to be a parameter $d=t$.\n",
    "\n",
    "### We solve the system for $c$, $b$, and $a$ in terms of the free parameter $t$ by plugging in the found values at each step:\n",
    "## $$ \\begin{array} {rcl} d & = & t \\\\ c & = & d = t \\\\ b & = & d=t \\\\ a & = & c+d=2t \\end{array} $$\n",
    "\n",
    "### Written as vectors, the solutions to the system have the form\n",
    "## $$ \\begin{pmatrix} a \\\\ b \\\\ c \\\\ d \\end{pmatrix} = t \\begin{pmatrix} 2 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $$\n",
    "### where $t$ is any real number.\n",
    "\n",
    "### In other words, the solutions are exactly the scalar multiples of the vector $\\begin{pmatrix} 2 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$. In particular, there are infinitely many of them.\n",
    "\n",
    "### But the problem was to find the smallest positive integers $a$, $b$, $c$, and $d$ that balance the reaction.The smallest such integers occur when $t=1$, so the balanced chemical reaction is\n",
    "## $$ 2\\mathrm{N}\\mathrm{O}_2+\\mathrm{H}_2\\mathrm{O} \\longrightarrow \\mathrm{H} \\mathrm{N} \\mathrm{O}_2 + \\mathrm{H} \\mathrm{N} \\mathrm{O}_3 $$\n",
    "\n",
    "### ***Note***\n",
    "### We solved the system by converting the matrix to row echelon form. Let's now solve it again, by going further to find the reduced row echelon form. Once the matrix is in this form, each row expresses a pivot variable directly in terms of free variables, so we can write down the solution immediately.\n",
    "\n",
    "### $\\operatorname{rref}(\\bf{A})$:\n",
    "## $$ \\left( \\begin{array} {cccc|c} {\\color{red}{1}} & 0 & -1 & -1 & 0 \\\\ 0 & {\\color{red}{1}} & 0 & -1 & 0 \\\\ 0 & 0 & {\\color{red}{-1}} & 1 & 0 \\end{array} \\right) \\longrightarrow \\left( \\begin{array} {cccc|c} {\\color{red}{1}} & 0 & -1 & -1 & 0 \\\\ 0 & {\\color{red}{1}} & 0 & -1 & 0 \\\\ 0 & 0 & {\\color{red}{1}} & -1 & 0 \\end{array} \\right) \\longrightarrow \\left( \\begin{array} {cccc|c} {\\color{red}{1}} & 0 & 0 & -2 & 0 \\\\ 0 & {\\color{red}{1}} & 0 & -1 & 0 \\\\ 0 & 0 & {\\color{red}{1}} & -1 & 0 \\end{array} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b97d14-ca91-4844-a3a9-e71832343879",
   "metadata": {},
   "source": [
    "### ***Using reduced row echelon form***\n",
    "\n",
    "### Let $\\bf{R}$ be the reduced row echelon form $\\operatorname{rref}(\\bf{A})$. Then the solutions to $\\bf{A}\\bf{x} = \\bf{0}$ are the same as the solutions to $\\bf{R}\\bf{x} = \\bf{0}$, which is the system\n",
    "## $$ \\begin{array} {rcl} a - 2d & = & 0 \\\\ b-d & = & 0 \\\\ c-d & = & 0 \\end{array} $$\n",
    "\n",
    "### The ***pivot variables*** are $a$, $b$, and $c$. The only ***free variable*** is $d$. We set the free variable $d$ equal to a parameter, say $t$. For each pivot variable, there is an equation expressing it in terms of $d$, so we can immediately write down the general solution in terms of $t$:\n",
    "## $$ \\begin{array} {rcl} d & = & t \\\\ a & = & 2t \\\\ b & = & t \\\\ c & = & t \\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df5ef5-6945-49a0-9e39-2349002ba270",
   "metadata": {},
   "source": [
    "## Worked example: solving a homogeneous linear system\n",
    "\n",
    "### ***Problem 3.1***\n",
    "### The reduced row echelon form of the matrix\n",
    "## $$ \\bf{A} = \\begin{pmatrix} 0 & 0 & 6 & 2 & -4 & -8 \\\\ 0 & 0 & 3 & 1 & -2 & -4 \\\\ 2 & -3 & 1 & 4 & -7 & 1 \\\\ 6 & -9 & 0 & 11 & -19 & 3 \\end{pmatrix} $$\n",
    "### is the matrix\n",
    "## $$ \\operatorname{rref}(\\bf{A}) = \\begin{pmatrix} 1 & -\\frac{3}{2} & 0 & \\frac{11}{6} & -\\frac{19}{6} & 0 \\\\ 0 & 0 & 1 & \\frac{1}{3} & -\\frac{2}{3} & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 1 \\\\ 0 & 0 & 0 & 0 & 0 & 0 \\end{pmatrix} $$\n",
    "\n",
    "### Find all solutions to the homogenous linear system $\\bf{A}\\bf{x} = \\bf{0}$.\n",
    "\n",
    "### ***Definition 3.2*** \n",
    "### The set of all solutions to a homogenous linear system $\\bf{A}\\bf{x} = \\bf{0}$ is called the ***nullspace of matrix $\\bf{A}$***, and is denoted $\\operatorname{NS}(\\bf{A})$.\n",
    "\n",
    "### ***Solution***\n",
    "### First note that each variable corresponds to a column in the reduced row echelon matrix\n",
    "## $$ \\begin{array} {c} { \\begin{array} {cccccc} {\\color{red}{\\,\\,x\\,}} & {\\color{orange}{\\,\\,y}} & {\\color{red}{\\,z\\,}} & {\\color{orange}{u\\,}} & {\\color{orange}{\\,\\,\\,v\\,}} & {\\color{red}{\\,\\,w\\,}} \\end{array} } \\\\ { \\left( \\begin{array} {cccccc} {\\color{red}{1}} & -\\frac{3}{2} & 0 & \\frac{11}{6} & -\\frac{19}{6} & 0 \\\\ 0 & 0 & {\\color{red}{1}} & \\frac{1}{3} & -\\frac{2}{3} & 0 \\\\ 0 & 0 & 0 & 0 & 0 & {\\color{red}{1}} \\\\ 0 & 0 & 0 & 0 & 0 & 0 \\end{array} \\right) } \\end{array} $$\n",
    "\n",
    "### Any column that contains a pivot is called a ***pivot column***. A variable whose corresponding column is a pivot column is called a ***dependent variable*** or ***pivot variable***. The other variables are called ***free variables***. In this problem, ${\\color{red}{x}}$, ${\\color{red}{z}}$, ${\\color{red}{w}}$ are dependent variables, and ${\\color{orange}{y}}$, ${\\color{orange}{u}}$, ${\\color{orange}{v}}$ are ***free variable***s.\n",
    "\n",
    "### Let $\\bf{x} = \\begin{pmatrix} {\\color{red}{x}} \\\\ {\\color{orange}{y}} \\\\ {\\color{red}{z}} \\\\ {\\color{orange}{u}} \\\\ {\\color{orange}{v}} \\\\ {\\color{red}{w}} \\end{pmatrix} $. The the system $\\bf{A}\\bf{x} = \\bf{0}$ is equivalent to the system of equations\n",
    "## $$ \\begin{array} {rcl} {\\color{red}{x}} - \\frac{3}{2} {\\color{orange}{y}} + \\frac{11}{6} {\\color{orange}{u}} - \\frac{19}{6} {\\color{orange}{v}} & = & 0 \\\\ {\\color{red}{z}} + \\frac{1}{3}{\\color{orange}{u}}-\\frac{2}{3}{\\color{orange}{v}} & = & 0 \\\\ {\\color{red}{w}} & = & 0 \\\\ 0 & = & 0 \\end{array} $$\n",
    "### The last equation gives us no information so we discard it.\n",
    "## $$ \\begin{array} {rcl} {\\color{red}{x}} - \\frac{3}{2} {\\color{orange}{y}} + \\frac{11}{6} {\\color{orange}{u}} - \\frac{19}{6} {\\color{orange}{v}} & = & 0 \\\\ {\\color{red}{z}} + \\frac{1}{3}{\\color{orange}{u}}-\\frac{2}{3}{\\color{orange}{v}} & = & 0 \\\\ {\\color{red}{w}} & = & 0 \\end{array} $$\n",
    "\n",
    "### Note that because we used the reduced row echelon form to solve this system, each equation directly expressed one pivot variable as a linear combination of the free variables. Start by assigning parameters to each of the free variables.\n",
    "## $$ \\begin{array} {rclr} {\\color{orange}{y}} & = & c_1 & \\text{for a parameter}\\, c_1 \\\\ {\\color{orange}{u}} & = & c_2 & \\text{for a parameter}\\, c_2 \\\\ {\\color{orange}{v}} & = & c_3 & \\text{for a parameter}\\, c_3 \\\\  \\end{array} $$\n",
    "\n",
    "### Next express each pivot variable in terms of the parameters.\n",
    "## $$ \\begin{array} {rcl} {\\color{red}{x}} & = & \\frac{3}{2}{\\color{orange}{y}} - \\frac{11}{6}{\\color{orange}{u}}+\\frac{19}{6}{\\color{orange}{v}} = \\frac{3}{2}c_1 - \\frac{11}{6}c_2+\\frac{19}{6}c_3 \\\\ {\\color{red}{z}} & = & -\\frac{1}{3}{\\color{orange}{u}}+\\frac{2}{3}{\\color{orange}{v}}=-\\frac{1}{3}c_2+\\frac{2}{3}c_3 \\\\ {\\color{red}{w}} & = & 0 \\end{array} $$\n",
    "\n",
    "### Therefore the general solution is given by\n",
    "## $$ \\begin{pmatrix} {\\color{red}{x}} \\\\ {\\color{orange}{y}} \\\\ {\\color{red}{z}} \\\\ {\\color{orange}{u}} \\\\ {\\color{orange}{v}} \\\\ {\\color{red}{w}} \\end{pmatrix}  = \\begin{pmatrix} \\frac{3}{2}c_1-\\frac{11}{6}c_2+\\frac{19}{6}c_3 \\\\ c_1 \\\\ -\\frac{1}{3}c_2 + \\frac{2}{3}c_3 \\\\ c_2 \\\\ c_3 \\\\ 0 \\end{pmatrix} $$\n",
    "## $$ = \\begin{pmatrix} \\frac{3}{2}c_1 \\\\ c_1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} -\\frac{11}{6}c_2 \\\\ 0 \\\\ -\\frac{1}{3}c_2 \\\\ c_2 \\\\ 0 \\\\ 0 \\end{pmatrix}  + \\begin{pmatrix} \\frac{19}{6}c_3 \\\\ 0 \\\\ \\frac{2}{3}c_3 \\\\ 0 \\\\ c_3 \\\\ 0 \\end{pmatrix} $$\n",
    "## $$ = c_1 \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} + c_2 \\begin{pmatrix} -\\frac{11}{6} \\\\ 0 \\\\ -\\frac{1}{3} \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}  + c_3 \\begin{pmatrix} \\frac{19}{6} \\\\ 0 \\\\ \\frac{2}{3} \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $$\n",
    "\n",
    "### In particular, each of the three vectors\n",
    "## $$ \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} -\\frac{11}{6} \\\\ 0 \\\\ -\\frac{1}{3} \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} \\frac{19}{6} \\\\ 0 \\\\ \\frac{2}{3} \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $$\n",
    "### is a solution to the original homogenous equation. And the set of all solutions is found by taking all linear combinations of these solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad2597-ecf9-4892-89bb-d5ff03b0ed31",
   "metadata": {},
   "source": [
    "## The geometry of solutions to homogeneous linear systems\n",
    "\n",
    "### Consider the vector space $\\mathbb{R}^3$. This is a $3$ dimensional vector space. If we have one equation, $a x + b+cz=0$, where $a$, $b$, and $c$ are not all zeros, then the solutions to this equation describe a plane through the origin. Therefore the dimension of the solution space is $2$, which is one less than all possible vectors in $\\mathbb{R}^3$. If we add a second equation what happens?\n",
    "\n",
    "### When we add a second equation, the dimension of the solution space can at most decrease by $1$ again. However, if the second equation describes the same plane as the first equation, the solution set remains unchanged!\n",
    "\n",
    "### ***Principle***:\n",
    "### Each additional equation (of the form $ax+by+cz=0$) reduces the dimension of the solution space by at most $1$. Therefore $m$ equations reduces the dimension of the solution space by at most $m$.\n",
    "\n",
    "### If our $m$ equations have $n$ variables, then we started with the $n$ dimensional space $\\mathbb{R}^3$. The smallest possible dimension of the solution space is $n-m$. This suggests that for a general system with $m$ equations in $n$ variables, the dimension of the solution space is at most $n$ and at least $n-m$ since each equation cuts the dimension of the solution space by at most $1$.\n",
    "\n",
    "### Reformulated in terms of matrices, this says that for an $m$ by $n$ matrix $\\bf{A}$, the solution space to the homogeneous equation $\\bf{A}\\bf{x} = \\bf{0}$ can be at most be $n$ dimensional, and at least $n-m$ dimensional. By the end of this lecture, we'll make what we mean by $n$ dimensions more precise, and we will have an algorithm for determining the dimension of the solutions to any homogeneous system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70ad4e-0880-4dae-8da2-8db7fe60cc24",
   "metadata": {},
   "source": [
    "## Vector spaces\n",
    "\n",
    "### ***The geometry of vectors***\n",
    "\n",
    "### Our ability to visualize vectors in dimensions larger than $2$ or $3$ limits our ability to draw images. But we continue to use our geometric intuition in lower dimensions to inform our algebraic treatment of higher dimensional vectors.\n",
    "![Visualization](img/visual.png)\n",
    "\n",
    "### A video refresher if needed: [Vectors, what are they?](https://www.youtube.com/watch?v=fNk_zzaMoSs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279ea2a-84e6-4867-80a8-c531d03cc9ca",
   "metadata": {},
   "source": [
    "### ***Vector spaces***\n",
    "### We know that vectors can be added together,\n",
    "## $$ \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix} + \\begin{pmatrix} -1 \\\\ 1 \\\\ -1 \\\\ 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1 -1 \\\\ 2 +1 \\\\ 3 - 1\\\\ 4 + 1 \\\\ 5 - 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 3 \\\\ 2 \\\\ 5 \\\\ 4 \\end{pmatrix} $$\n",
    "### or they can be multiplied by a real (or complex) scalar\n",
    "## $$ c \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix} = \\begin{pmatrix} 1c \\\\ 2c \\\\ 3c \\\\ 4c \\\\ 5c \\end{pmatrix} $$\n",
    "\n",
    "### A set of vectors is called ***closed under addition*** if the sum of any vectors is in the set. \n",
    "### Similarly a set of vectors is ***closed under scalar multiplication*** if for every scalar $c$ and vector $\\bf{x}$ the vector $c\\bf{x}$ is in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4e0ea-dc34-4f4b-9a55-37018f96fffd",
   "metadata": {},
   "source": [
    "### ***Example 5.1***\n",
    "### Solutions to homogenous linear systems $\\bf{A}\\bf{x} =\\bf{0}$ are closed under multiplication and (vector) addition:\n",
    "### 1. (Closed under scalar multiplication.) If $\\bf{x_1}$ is a solution, then $\\bf{A}c\\bf{x} = c\\bf{A}\\bf{x_1} = c\\bf{0} = 0$ implies that $c\\bf{x_1}$ is also a solution.\n",
    "### 2. (Closed under addition.) If $\\bf{x_1}$ and $\\bf{x_2}$ are two solutions then\n",
    "## $$ \\bf{A}(\\bf{x_1}+\\bf{x_2}) = \\bf{A} \\bf{x_1} + \\bf{A} \\bf{x_2} = 0 + 0 $$\n",
    "### implies that $\\bf{x_1} + \\bf{x_2}$ is also a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc95877-b58d-4e21-af0d-bd45a9f81d92",
   "metadata": {},
   "source": [
    "## The notion of a ***vector space*** captures these properties.\n",
    "### ***Definition 5.2***\n",
    "### A ***vector space*** (of vectors) over the real (or complex) numbers is a set $\\bf{V}$ such that\n",
    "### 0. The zero vector $\\bf{0}$ is in $\\bf{V}$\n",
    "### 1. Multiplying any one vector $\\bf{v}$ in $\\bf{V}$ by a real (or complex) scalar $c$ gives another vector $c\\bf{v}$ which is also in $\\bf{V}$\n",
    "### 2. Adding any two vectors $\\bf{v}$ and $\\bf{w}$ in $\\bf{V}$ gives another vector $\\bf{u} = \\bf{v} + \\bf{w}$ also in $\\bf{V}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e7320-7189-4e68-bdfe-f40bc1a6b22f",
   "metadata": {},
   "source": [
    "### ***More examples***\n",
    "\n",
    "### - The set of real numbers $\\mathbb{R}$ can be thought of as a vector space.\n",
    "\n",
    "### - The plane $\\mathbb{R}^2$ is the vector space given by the set\n",
    "## $$ \\mathbb{R}^2 = \\{ \\text{all} \\, \\bf{v} = \\begin{pmatrix} c_1 \\\\ c_2 \\end{pmatrix} \\, \\text{with}\\, c_1, c_2\\, \\text{real numbers} \\} $$\n",
    "\n",
    "### - A line $\\bf{L}$ through th origin in the plane is a vector space. This equals the set of all scalar multiples of one nonzero vector $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$:\n",
    "## $$ \\bf{L}^2 = \\{ \\text{all} \\, c \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\, \\text{with}\\, c \\, \\text{any real numbers},\\, a, b \\, \\text{fixed}  \\} $$\n",
    "\n",
    "### - The vector space $\\mathbb{R}^n$ is the set of all vectors $\\begin{pmatrix} c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n \\end{pmatrix}$ where $c_1, \\ldots, c_n$ are real numbers.\n",
    "\n",
    "### - The complex vector space $\\mathbb{C}^2$ is the set of all vectors with complex entries:\n",
    "## $$ \\{ \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix}\\, \\text{such that}\\, z_1, z_2\\,\\text{are complex numbers} \\} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba0acd-1904-45f9-bf9f-9bf1c9adf390",
   "metadata": {},
   "source": [
    "### ***Nonexample***\n",
    "\n",
    "### The set in $\\mathbb{R}^2$ consisting of the single point $\\left\\{ \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right\\}$ is not a vector space. It fails all three conditions.\n",
    "### 0. The point $\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} $ is not in the set.\n",
    "### 1. The scalar multiple $-1 \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}$ is not in the set.\n",
    "### 2. The sum $\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} $ is not in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80ddc4-ce02-4d33-a9b4-e78507ebfbea",
   "metadata": {},
   "source": [
    "## Subspaces\n",
    "### ***Subspaces*** are subsets of vector spaces that are by themselves vector spaces.\n",
    "\n",
    "### ***Example 6.1***\n",
    "### Subspaces of $\\mathbb{R}^2$ (it turns out that this is the complete list):\n",
    "### - $\\{ \\bf{0} \\}$ (the set containing only the origin),\n",
    "### - any line through the origin,\n",
    "### - the whole plane $\\mathbb{R}^2$.\n",
    "\n",
    "### ***Example 6.2***\n",
    "### Subspaces of $\\mathbb{R}^3$ (again, the complete list):\n",
    "### - $\\{ \\bf{0} \\}$ ,\n",
    "### - any line through the origin,\n",
    "### - any plane through the origin,\n",
    "### - the whole space $\\mathbb{R}^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec5339-9e28-4755-8a6f-ad7baf0f33be",
   "metadata": {},
   "source": [
    "## Example problem\n",
    "\n",
    "### The set of linear combinations of the vectors $\\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\end{pmatrix}$ and $\\begin{pmatrix} 1 \\\\ 4 \\\\ 5 \\end{pmatrix}$ is a subspace of $\\mathbb{R}^3$\n",
    "\n",
    "### 0. The zero vector is obtained by taking the zero combination:\n",
    "## $$ 0 \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\end{pmatrix} + 0 \\begin{pmatrix} 1 \\\\ 4 \\\\ 5 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\n",
    "\n",
    "### 1. If a vector $\\bf{v}$ can be written as a linear combination of the two vectors:\n",
    "## $$ \\bf{v} = a \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\end{pmatrix} + b \\begin{pmatrix} 1 \\\\ 4 \\\\ 5 \\end{pmatrix} $$\n",
    "### then so can $c\\bf{v}$:\n",
    "## $$ c\\bf{v} = c a \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\end{pmatrix} + c b \\begin{pmatrix} 1 \\\\ 4 \\\\ 5 \\end{pmatrix} $$\n",
    "\n",
    "### 2. If two vectors $\\bf{v}$ and $\\bf{w}$ can be written as a linear combination of the two vectors:\n",
    "## $$ \\bf{v} = a_1 \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\end{pmatrix} + b_1 \\begin{pmatrix} 1 \\\\ 4 \\\\ 5 \\end{pmatrix}, \\quad \\bf{w} = a_2 \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\end{pmatrix} + b_2 \\begin{pmatrix} 1 \\\\ 4 \\\\ 5 \\end{pmatrix} $$\n",
    "### then so can $\\bf{v} + \\bf{w}$\n",
    "## $$ \\bf{v} + \\bf{w} = (a_1 + a_2) \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\end{pmatrix} + (b_1 + b_2) \\begin{pmatrix} 1 \\\\ 4 \\\\ 5 \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37936d-60b1-4b67-8d6b-758e90d7aca1",
   "metadata": {},
   "source": [
    "## Nullspace\n",
    "\n",
    "### Here is what happens in general for homogeneous linear systems:\n",
    "### Recall that the set of all solutions to a homogeneous linear system $\\bf{A}\\bf{x} = \\bf{0}$ is called the ***nullspace of matrix*** $\\bf{A}$, and is denoted $\\operatorname{NS}(\\bf{A})$.\n",
    "\n",
    "### ***Theorem 7.1***\n",
    "### If $\\bf{A}$ is a matrix, then the set of all solutions to the homogeneous linear system $\\bf{A}\\bf{x} = \\bf{0}$ is a vector space. (In other words if $\\bf{A}$ is an $m \\times n$ matrix, then the nullspace $\\operatorname{NS}(\\bf{A})$ is a subspace of $\\mathbb{R}^n$.)\n",
    "\n",
    "### ***Analogous theorem***: \n",
    "### If $P(D)$ is a linear differential operator, then the set of solutions to the homogeneous ODE $P(D) x = 0$ is a vector space of functions. (It is a subspace of the set of all functions.)\n",
    "\n",
    "### ***Proof of the theorem***\n",
    "### We already showed that the solutions to $\\bf{A}\\bf{x} = \\bf{0}$ satisfy the definition of a vector space. (In fact we used this to motivate our definition of a vector space.) We replicate the proof here for completeness.\n",
    "\n",
    "### 0. $\\bf{A} \\bf{0} = \\bf{0}$ implies that $\\bf{0}$ is in the nullspace.\n",
    "### 1. If $\\bf{x}$ is in nullspace, this means that $\\bf{A}\\bf{x} = 0$. Then\n",
    "## $$ \\bf{A} (c \\bf{x}) = c \\bf{A} \\bf{x} = c \\bf{0} = \\bf{0} $$\n",
    "### Thus $c \\bf{x}$ i also in the nullspace\n",
    "\n",
    "### 2. If $\\bf{x_1}$ ad $\\bf{x_2}$ are in the nullspace, this means that $\\bf{A} \\bf{x_1} = \\bf{0}$ and $\\bf{A} \\bf{x_2} = \\bf{0}$. Then\n",
    "## $$ \\bf{A} (\\bf{x_1} + \\bf{x_2}) = \\bf{A} \\bf{x_1} + \\bf{A} \\bf{x_2} = \\bf{0} + \\bf{0} = \\bf{0}$$\n",
    "### Thus $\\bf{x_1} + \\bf{x_2}$ is also in the nullspace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e090d92-cc60-483f-a07b-0fddc4d08863",
   "metadata": {},
   "source": [
    "## Linear combinations and span\n",
    "\n",
    "### A ***linear combination*** of vectors $\\bf{v_1}, \\ldots, \\bf{v_n}$ is a vector of the form $c_1 \\bf{v_1} + \\ldots + c_n \\bf{v_n}$ for some real (or complex) scalars $c_1, \\ldots, c_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dfabc2-0bd3-4fae-a9c8-a882a0041f0b",
   "metadata": {},
   "source": [
    "### ***Definition 8.1***\n",
    "### Given vectors $\\bf{v_1}, \\ldots, \\bf{v_n}$, the ***span*** of $\\bf{v_1}, \\ldots, \\bf{v_n}$ is the set of ***all*** linear combinations of $v_1, \\ldots, v_n$:\n",
    "## $$ \\operatorname{Span}(\\bf{v_1}, \\ldots, \\bf{v_n}) = \\{ \\text{all vectors}\\, c_1\\bf{v_1} + \\ldots + c_n \\bf{v_n}, \\, \\text{where}\\, c_1,\\ldots,c_n\\,\\text{are scalars} \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266576e-91b5-4051-9157-c72bf426098b",
   "metadata": {},
   "source": [
    "### ***Example 8.2***\n",
    "### If $\\bf{v} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$, then $\\operatorname{Span}(\\bf{v})=\\left\\{ c \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right\\}$ where $c$ is the scalar on the line $y = x$ in $\\mathbb{R}^2$\n",
    "![Span](img/span.png)\n",
    "\n",
    "### Notice that $\\operatorname{Span}(\\bf{v})$ is an infivinite set of vectors because it contains $\\begin{pmatrix} c \\\\ c \\end{pmatrix}$ for every real number $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65664f58-ba12-477e-a926-b643fa768d13",
   "metadata": {},
   "source": [
    "### ***Example 8.3***\n",
    "### The subspace $\\operatorname{Span}\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\\right)$ is the same subspace defined in the previous example. The vector $\\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}$ is in the span $\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $, since\n",
    "## $$ \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} = 2 \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\n",
    "\n",
    "### Therefore there are no new vectors in this subspace,\n",
    "## $$ \\operatorname{Span}\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\\right) = \\operatorname{Span}\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\right) $$\n",
    "### This is the line $y = x$ in $\\mathbb{R}^2$\n",
    "\n",
    "### ***Remark***: Sometimes we are lazy, and use a single parenthesis for the span of a single vector: $\\operatorname{Span}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ rather than $\\operatorname{Span}\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9f8a9-b7ca-4d9d-8a76-0f795d63bd92",
   "metadata": {},
   "source": [
    "### ***Example 8.4***\n",
    "### If $\\bf{e_1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$ and $\\bf{e_2} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$, then $\\operatorname{Span}(\\bf{e_1}, \\bf{e_2})$ is the set of all vectors of the form\n",
    "## $$ c_1\\bf{e_1}+c_2\\bf{e_2} = \\begin{pmatrix} c_1 \\\\ c_2 \\\\ 0 \\end{pmatrix} $$\n",
    "### These form the $xy$-plane in $\\mathbb{R}^3$, whose equation is $z = 0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25022c-dfc4-4118-b70e-6f49b92afb8d",
   "metadata": {},
   "source": [
    "### Note that in all of the examples above, the span is subspace. \n",
    "### In fact the span is always a vector space. \n",
    "### The reason we talk about span is because it gives a compact notation for describing an infinite set of vectors that form a subspace.\n",
    "### For example, the set of solutions to a homogenous linear equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef03ab-83e5-4df1-ac76-3367627927f5",
   "metadata": {},
   "source": [
    "### ***Example 8.5***\n",
    "### In our second example of solving the homogenous linear system $\\bf{A} \\bf{x} = \\bf{0}$, we found the solutions were of the form\n",
    "\n",
    "## $$ c_1 \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} + c_2 \\begin{pmatrix} -\\frac{11}{6} \\\\ 0 \\\\ -\\frac{1}{3} \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}  + c_3 \\begin{pmatrix} \\frac{19}{6} \\\\ 0 \\\\ \\frac{2}{3} \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $$\n",
    "\n",
    "### That is, set of solutions to the homogenous linear systems (or nullspace) is the span\n",
    "## $$ \\operatorname{NS}(\\bf{A}) = \\{ \\text{the set of solutions to}\\,\\bf{A}\\bf{x}=\\bf{0} \\} = \\operatorname{Span}\\left( \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} -\\frac{11}{6} \\\\ 0 \\\\ -\\frac{1}{3} \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} \\frac{19}{6} \\\\ 0 \\\\ \\frac{2}{3} \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e899dc-f2af-4095-9cb3-7ace9466cd15",
   "metadata": {},
   "source": [
    "### ***Definition 8.6***\n",
    "### Given a matrix $\\bf{A}$, whose columns are the vectors $\\bf{v_1}, \\ldots, \\bf{v_n}$, the span of these columns is a vectors space which we call the ***column space of*** $\\bf{A}$, and denote using the notation $\\operatorname{CS}(\\bf{A})$\n",
    "## $$ \\operatorname{CS}(\\bf{A}) = \\operatorname{Span}(\\text{columns of}\\,\\bf{A}) = \\operatorname{Span}(\\bf{v_1}, \\ldots, \\bf{v_n}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79c379-facd-44d5-9d29-18bbef985bc6",
   "metadata": {},
   "source": [
    "### An optional video on span and linear independence: [Linear combinations, span, and basis vectors](https://www.youtube.com/watch?v=k7RM-ot2NWY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbe5f2-ee42-48e2-a22b-17fbeb1841c0",
   "metadata": {},
   "source": [
    "## Linear dependence and independence\n",
    "\n",
    "### When we describe the set of solutions to $\\bf{A}\\bf{x} =\\bf{0}$ as the span of a set of vectors, we want this set of vectors to be as small as possible. In order to eliminate redundant vectors, we need to generalize the notion of linear dependence to 3 or more vectors.\n",
    "\n",
    "### ***Example 10.1***\n",
    "### On the previous page, we saw that $\\operatorname{Span}\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} , \\begin{pmatrix}2 \\\\ 2 \\end{pmatrix} \\right) = \\operatorname{Span}\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right)$. This is because the vector $\\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}$ is in the span of $\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. In this case, it may seem obvious that this vector is only adding redundant information because it is a scalar multiple of the other vector. We had a term to describe this, we say that these two vectors are ***linearly dependent***.\n",
    "\n",
    "### What does it mean for 3 or more vectors to be linearly dependent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7229456d-ed55-49e2-978d-fcafae72b265",
   "metadata": {},
   "source": [
    "### ***Example 10.2***\n",
    "### Determine if there are any redundant vectors used to define the subspace\n",
    "## $$ \\operatorname{Span}\\left( \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} , \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}  \\right) $$\n",
    "\n",
    "### To start, let's see if all vectors are in the span of one vector $\\operatorname{Span}\\left( \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\right)$.\n",
    "### If this is the case, we could write $\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $ and $\\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} $ as $c \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $ for some value $c$. This is not possible. So at most one vector is redundant.\n",
    "### Let's now consider the space $\\operatorname{Span}\\left( \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}  \\right)$.\n",
    "### We ask if $\\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} $ lies in this subspace. If it does, then t does not add any new information. We see that in fact, it is in this span because\n",
    "## $$ \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $$\n",
    "### This idea of redundence is captured in the definition of what it means for 3 or more vectors to be linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76322dc5-d1eb-4f2b-8bd1-a706af5e68f9",
   "metadata": {},
   "source": [
    "### ***Geometric definition***:\n",
    "### A collection of vectors $\\bf{v_1}, \\bf{v_2},\\bf{v_3},\\ldots,\\bf{v_n}$ is ***linearly dependent*** if there is at least one vector $\\bf{v_i}$ that lies in the subspace spanned by the other vectors.\n",
    "### Vectors that are not linearly dependent are called ***linearly independent***.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d402db-18a0-48be-a3c7-dd9bee1bf9d0",
   "metadata": {},
   "source": [
    "### ***Reduction to 2 vectors***:\n",
    "### ***Example 10.3***\n",
    "### Let's consider this definition of linear dependence in the case of two vectors: $\\bf{v_1},\\bf{v_2}$. These vectors are linearly dependent if one of these vectors, say $\\bf{v_j}$ is in the subspace $\\operatorname{Span}(\\bf{v_i})$. Since $\\operatorname{Span}(\\bf{v_i})=\\{c \\bf{v_i}, c \\, \\text{any number}\\}$, for $\\bf{v_j}$ to be in this subspace implies that $\\bf{v_j}=c \\bf{v_i}$ for some number $c$. This is equivalent to saying that both vectors lie on the same line through the origin, that is one is a scalar multiple of the other. (This was the definition we gave for linear dependence of two vectors.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c580454-5507-4661-a019-a3b9f99a7b35",
   "metadata": {},
   "source": [
    "### ***More small examples:***\n",
    "### ***Example 10.4***\n",
    "### The vectors $\\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix} , \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} $ and $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $ are linearly dependent because $\\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix} $ is in the span of $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} $ and $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $:\n",
    "## $$ \\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix}  = 3 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}  + 5 \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa98d18-1572-484e-a364-ee933b96b2c7",
   "metadata": {},
   "source": [
    "### ***Example 10.5*** \n",
    "### Are $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} , \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $ and $\\begin{pmatrix} 2 \\\\ 0 \\\\ 0 \\end{pmatrix} $ linearly dependent?\n",
    "### The vector $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} $ is not in the span of $\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $ and $\\begin{pmatrix} 2 \\\\ 0 \\\\ 0  \\end{pmatrix} $, but we don't know yet if they are linearly independent. \n",
    "### They are linearly dependent because $\\begin{pmatrix} 2 \\\\ 0 \\\\ 0 \\end{pmatrix} $ is in the span of $\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $ and $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e77e6-e67e-4cfa-af6a-543cf14e7af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
