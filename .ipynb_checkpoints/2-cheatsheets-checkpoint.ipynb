{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc1448f-7d3f-4dae-baf9-f119336d7a21",
   "metadata": {},
   "source": [
    "# Unit 2: Linear Algebra, Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923cb855-32fb-435c-be28-8caaef479a01",
   "metadata": {},
   "source": [
    "## Example: a projection\n",
    "\n",
    "### Let $\\bf{f}$ be the function from $\\mathbb{R}^3$ to $\\mathbb{R}^3$ that projects all of $\\mathbb{R}^3$ onto the $xy$-plane:\n",
    "## $$ \\bf{f} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} x \\\\ y \\\\ 0 \\end{pmatrix} $$\n",
    "\n",
    "### 1. What is the matrix $\\bf{A}$ that represents $\\bf{f}$?\n",
    "### 2. Which vectors from the input vector spae does $\\bf{f}$ map to $\\bf{0}$?\n",
    "### 3. Describe the range (or omage) of $\\bf{f}$ geometrically in the output space. Recall that the range of $\\bf{f}$ is the set of all vectors $\\bf{b} = \\bf{f}(\\bf{x})$ for all vectors $\\bf{x}$ in the input space.\n",
    "\n",
    "### ***Solution***:\n",
    "### 1. $\\bf{A}$ is a $3 \\times 3$ matrix such that\n",
    "## $$ \\begin{array} {lcccr} (\\text{first column of}\\,\\bf{A}) & = & \\bf{f} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} & = & \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\\\ (\\text{second column of}\\,\\bf{A}) & = & \\bf{f} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} & = & \\begin{pmatrix} 0 \\\\ 1 \\\\ 0  \\end{pmatrix} \\\\ (\\text{third column of}\\,\\bf{A}) & = & \\bf{f} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} & = & \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\end{array} $$\n",
    "\n",
    "### Thus $\\bf{A} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} $.\n",
    "\n",
    "### 2. Note that $\\bf{f} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} x \\\\ y \\\\ 0 \\end{pmatrix} $ is the zero vector if and only if $x = 0$ and $y = 0$. Thus the projection takes any vector of the form $\\begin{pmatrix} 0 \\\\ 0 \\\\ z \\end{pmatrix}$ to the zero vector. Geometrically, this says that the entire $z$-axis is sent to the zero vector.\n",
    "![Projection](img/projection.png)\n",
    "\n",
    "### The set of vectors mapped to $\\bf{0}$ by $\\bf{f}$ is the same as the set of solutions to $\\bf{A} \\bf{x} = \\bf{0}$. \n",
    "### Using our algorithm from the last lecture, we find the set of solutions to $\\bf{A}\\bf{x} = \\bf{0}$. \n",
    "### This set of solutions forms a vector space called the ***nullspace***. The nullspace $\\operatorname{NS}(\\bf{A})$ is a subspace of the ***input*** space; in this example:\n",
    "## $$ \\begin{array} {rcl} \\operatorname{NS}(\\bf{A}) & = & \\{ \\text{solutions to}\\, \\bf{A}\\bf{x} = \\bf{0} \\} \\\\ \\, & = & \\{ \\text{solutions to}\\,\\bf{f}(x,y,z) = \\bf{0} \\} \\\\ \\, & = & \\{ (0, 0, z): z \\in \\mathbb{R} \\} \\\\ \\, & = & \\text{the }\\, z\\text{-axis in the input space}\\, \\mathbb{R}^3 \\end{array} $$\n",
    "\n",
    "### 3. The set of all vectors $\\bf{b}$ in the image (also called range) of $\\bf{f}$ are all vectors $\\bf{f}(\\bf{x})$; in our example:\n",
    "## $$ \\begin{array} {rcl} \\text{Image of}\\,\\bf{f}(x,y,z) & = & \\{ (x, y, 0): x,y \\in \\mathbb{R} \\} \\\\ \\, & = & \\text{the }\\, xy\\text{-plane in the output space}\\, \\mathbb{R}^3 \\end{array} $$\n",
    "\n",
    "### Another way of thinking of this is as the set of all vectors $\\bf{f}$ that can be written as $\\bf{A}\\bf{x}$ for some vector $\\bf{x}$; in our example:\n",
    "## $$ \\text{All vectors}\\, \\bf{A}\\bf{x} = \\text{all linear combinations of the columns of }\\,\\bf{A} $$\n",
    "\n",
    "### Therefore the set of al vectors $\\bf{b} = \\bf{A}\\bf{x}$ is the same as the span of the columns of $\\bf{A}$. \n",
    "### The span of the columns of $\\bf{A}$ is called the ***column space*** $\\operatorname{CS}(\\bf{A})$; it is a subspace of the ***output space***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24f608-d169-4c18-8995-4d71d50d206c",
   "metadata": {},
   "source": [
    "## Column space\n",
    "\n",
    "### ***Definition 3.1***\n",
    "### The ***column space*** of a matrix $\\bf{A}$ is the span of its columns. \n",
    "### The notation for it is $\\operatorname{CS}(\\bf{A})$. \n",
    "### It is also called the ***image*** of $\\bf{A}$, and written $\\operatorname{Im}(\\bf{A})$\n",
    "\n",
    "### Since $\\operatorname{CS}(\\bf{A})$ is a span, it is vector space.\n",
    "\n",
    "### ***Example 3.2***\n",
    "### Consider a matrix $\\bf{A} = \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{pmatrix}$. Its column space is given by\n",
    "## $$ \\operatorname{CS}(\\bf{A}) = \\text{the span of} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ 6 \\end{pmatrix} $$\n",
    "\n",
    "### Using that the column vectors are all constant multiples of the vector $\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$, we find a basis for the column space consisting of the single vector $\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$, and find that $\\operatorname{CS}(\\bf{A})$ is the line $y = 2x$ in $\\mathbb{R}^2$.\n",
    "\n",
    "### ***Example 3.3***\n",
    "### Find a basis for the column space of the matrix\n",
    "## $$ \\bf{A} = \\begin{pmatrix} 1 & 2 & 3 \\\\ -1 & -2 & -3 \\\\ 1 & 2 & 3 \\\\ 0 & 0 & 9 \\end{pmatrix} $$\n",
    "\n",
    "### The column space is defined as $\\operatorname{Span}\\left( \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ -2 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ -3 \\\\ 3 \\\\ 9 \\end{pmatrix}  \\right)$. But the second vector is a multiple of the first vector, so it is redundant. Therefore, the column space can be described more simply as the span of the first and third columns:\n",
    "## $$ \\operatorname{CS}(\\bf{A}) = \\operatorname{Span}\\left( \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ -3 \\\\ 3 \\\\ 9 \\end{pmatrix}  \\right) $$\n",
    "### These two vectors are linearly independent, so we do need both vectors in the basis for this column space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ae9c8-78cf-4d4a-a792-6eef1a0c57b4",
   "metadata": {},
   "source": [
    "## Computing a basis for $\\operatorname{CS}(\\bf{A})$\n",
    "\n",
    "### Steps to compute a basis for $\\operatorname{CS}(\\bf{A})$:\n",
    "### 1. Perform Gaussian elimination to convert $\\bf{A}$ to a matrix $\\bf{B}$ in row echelon form.\n",
    "### 2. Identify the pivot columns of $\\bf{B}$.\n",
    "### 3. The corresponding columns of $\\bf{A}$ are a basis for $\\operatorname{CS}(\\bf{A})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf8af6-df30-434e-8490-0e8347e1e412",
   "metadata": {},
   "source": [
    "### ***Proof***\n",
    "### Recall that $\\bf{B}$ is a row echelon form of $\\bf{A}$. Let $\\bf{C}$ be the ***reduced row*** echelon form of $\\bf{A}$. If\n",
    "## $$ \\text{fifth column} = 3(\\text{first column})+7(\\text{second column}) $$\n",
    "### is true for a matrix, it will remain true after any row operation.\n",
    "\n",
    "### Similarly, any linear relation between columns is preserved by row operations. So the linear relations between columns of $\\bf{A}$ are the same as the linear relations between columns of $\\bf{C}$. The condition that certain numbered columns (say the first, second, and fourth) of a matrix form a basis is expressible in terms of which linear relations hold. So if certain columns form a basis for $\\operatorname{CS}(\\bf{C})$, the same numbered columns will form a basis for $\\operatorname{CS}(\\bf{A})$. \n",
    "### ***Warning***: these are very unlikely to be the same columns!\n",
    "\n",
    "### Recall that $\\bf{B}$ is a row echelon form of $\\bf{A}$. We can obtain the reduced row echelon form $\\bf{C}$ by performing Gauss-Jordan elimination on $\\bf{B}$. This process does not change the pivot locations. Thus it will be enough to show that the pivot columns of $\\bf{C}$ form a basis of $\\operatorname{CS}(\\bf{C})$. Since $\\bf{C}$ is in reduced row echelon form, the pivot columns of $\\bf{C}$ are the first $r$ of the $m$ standard basis vectors for $\\mathbb{R}^m$, where $r$ is the number of nonzero rows of $\\bf{C}$. These columns are ***linearly independent***, and every other column is a linear combination of them, since the entries of $\\bf{C}$ below the first $r$ rows are all zeros. Thus the pivot columns of $\\bf{C}$ form a basis of $\\operatorname{CS}(\\bf{C})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c98f9-a7ae-4e22-a0f5-aa597626dc34",
   "metadata": {},
   "source": [
    "### In particular\n",
    "## $$ \\dim \\operatorname{CS}(\\bf{A}) = \\# \\text{ pivot columns of }\\, \\bf{B} $$\n",
    "### ***Warning***\n",
    "### Usually $\\operatorname{CS}(\\bf{A}) \\neq \\operatorname{CS}(\\bf{B})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6322c-6d7f-46f3-a5bd-6d0dcf15767d",
   "metadata": {},
   "source": [
    "### ***Example***\n",
    "## $$ \\bf{A} = \\begin{pmatrix}  1 &  3 &  2 \\\\ -1 &  1 &  -2 \\\\ 2 &  3 &  4 \\end{pmatrix} $$\n",
    "## $$ \\bf{B} = \\operatorname{rref}(\\bf{A}) = \\begin{pmatrix}  1 &  3 &  2 \\\\ 0 &  4 &  0 \\\\ 0 &  0 &  0 \\end{pmatrix} $$\n",
    "### therefore\n",
    "## $$ \\text{basis for}\\, \\operatorname{CS}(\\bf{A}) = \\left\\{ \\begin{pmatrix}  1 \\\\ -1 \\\\ 2 \\end{pmatrix}, \\begin{pmatrix}  3 \\\\ 1 \\\\ 3 \\end{pmatrix} \\right\\} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774d36a-2287-4a7d-95f9-f849dd39b1a7",
   "metadata": {},
   "source": [
    "## Rank and the Rank-Nullity Theorem\n",
    "\n",
    "### ***Problem 4.1***\n",
    "### Let $\\bf{A}$ be the $3 \\times 5$ matrix\n",
    "## $$ \\begin{pmatrix}  1 &  2 &  3 &  4 &  5 \\\\ -1 &  -2 &  9 &  10 &  11 \\\\ 1 &  2 &  9 &  11 &  13 \\end{pmatrix} $$\n",
    "\n",
    "### 1. Find a basis for $\\operatorname{CS}(\\bf{A})$.\n",
    "### 2. What are $\\dim \\operatorname{NS}(\\bf{A})$ and $\\dim \\operatorname{CS}(\\bf{A})$?\n",
    "\n",
    "### ***Solution***\n",
    "### 1. First we find a row echelon form. Add the first row to the second, and add $-1$ times the first row to the third:\n",
    "## $$ \\begin{pmatrix}  1 &  2 &  3 &  4 &  5 \\\\ 0 &  0 &  12 &  14 &  16 \\\\ 0 &  0 &  6 &  7 &  8 \\end{pmatrix} $$\n",
    "### Add $-\\frac{1}{2}$ times the second row to the third:\n",
    "## $$ \\mathbf{B} \\colon = \\begin{pmatrix}  {\\color{red}{1}}  &  2 &  3 &  4 &  5 \\\\ 0 &  0 &  {\\color{red}{12}}  &  14 &  16 \\\\ 0 &  0 &  0 &  0 &  0 \\end{pmatrix} $$\n",
    "### This is row echelon form.\n",
    "### The pivots of $\\bf{B}$ are in the first and third columns.\n",
    "### Basis for $\\operatorname{CS}(\\bf{A})$: first and third columns of $\\bf{A}$, i.e., $\\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ 9 \\\\ 9 \\end{pmatrix}$.\n",
    "\n",
    "### 2.\n",
    "## $$ \\dim \\operatorname{NS}(\\bf{A}) = \\# \\text{non-pivot columns of}\\, \\bf{B} = 3 $$\n",
    "## $$ \\dim \\operatorname{CS}(\\bf{A}) = \\# \\text{pivot columns of}\\, \\bf{B} = 2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf161ae5-f9f2-4049-9a76-be52d4739e06",
   "metadata": {},
   "source": [
    "### ***Definition 4.2***\n",
    "### The ***nullity*** of $\\bf{A}$ is defined as the number\n",
    "## $$ \\operatorname{nullity}(\\bf{A}) = \\dim \\operatorname{NS}(\\bf{A}) $$\n",
    "\n",
    "### The ***rank*** of $\\bf{A}$ is defined as the number\n",
    "## $$ \\operatorname{rank}(\\bf{A}) = \\dim \\operatorname{CS}(\\bf{A}) $$\n",
    "\n",
    "### The rank of any $m \\times n$ matrix $\\bf{A}$ is always between $0$ and $\\min(m, n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f52ae-8e39-4a45-a2c4-fe890c034183",
   "metadata": {},
   "source": [
    "## Rank nullity theorem\n",
    "\n",
    "### ***Theorem 4.3***\n",
    "### For any $m \\times n$ matrix $\\bf{A}$,\n",
    "## $$ \\operatorname{nullity}(\\bf{A}) + \\operatorname{rank}(\\bf{A}) = n $$\n",
    "### This theorem is called ***rank-nullity theorem***.\n",
    "\n",
    "### ***Proof***\n",
    "### Let $\\bf{B}$ be a row echelon form of $\\bf{A}$.\n",
    "## $$ \\begin{array} {rcl} \\operatorname{nullity}(\\bf{A}) + \\operatorname{rank}(\\bf{A}) & = & \\dim \\operatorname{NS}(\\bf{A}) + \\dim \\operatorname{CS}(\\bf{A}) \\\\ \\, & = & (\\#\\text{non-pivot columns of }\\, \\bf{B})+(\\#\\text{pivot columns of}\\,\\bf{B}) \\\\ \\, & = & \\#\\text{columns of}\\,\\bf{B} \\\\ \\, & = & n \\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d594c-bb33-4ff7-b313-686beeef58d7",
   "metadata": {},
   "source": [
    "### When the rank of a matrix equals the number of its columns we say that this matrix has a ***full column rank***. \n",
    "### Whenever this happens, the matrix has a $0$-dimensional nullspace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ab2aa-7d75-4a98-992b-78ebd4830ced",
   "metadata": {},
   "source": [
    "## Computing a Basis for a Span\n",
    "\n",
    "### Given vectors $\\bf{v_1}, \\ldots, \\bf{v_n} \\in \\mathbb{R}^m$, how can one compute a basis of $\\operatorname{Span}(\\bf{v_1}, \\ldots,\\bf{v_n})$?\n",
    "\n",
    "### ***Algorithm for computing a basis for*** $\\operatorname{Span}(\\bf{v_1}, \\ldots,\\bf{v_n})$\n",
    "\n",
    "### 1. Form the matrix $\\bf{A}$ whose columns are $\\bf{v_1}, \\ldots, \\bf{v_n}$\n",
    "### 2. Find a basis for $\\operatorname{CS}(\\bf{A})$ (by using a row echelon form as discussed earlier)\n",
    "\n",
    "### ***Example 5.1***\n",
    "### Find a basis for the span of the following vctors:\n",
    "## $$ \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ -2 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ -3 \\\\ 3 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix} $$\n",
    "### Start by forming the matrix $\\bf{A} = \\begin{pmatrix} 1 & 2 & 3 & 0 \\\\ -1 & -2 & -3 & 0 \\\\ 1 & 2 & 3 & 0 \\\\ 0 & 0 & 1 & 1 \\end{pmatrix} $. Find the row echelon form of $\\bf{A}$ using Gaussian elimination:\n",
    "## $$ \\begin{pmatrix} 1 & 2 & 3 & 0 \\\\ -1 & -2 & -3 & 0 \\\\ 1 & 2 & 3 & 0 \\\\ 0 & 0 & 1 & 1 \\end{pmatrix} \\to \\begin{pmatrix} 1 & 2 & 3 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\end{pmatrix} \\to \\begin{pmatrix} 1 & 2 & 3 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix} $$\n",
    "\n",
    "### The pivot columns are the first and third columns, therefore a basis is given by\n",
    "## $$ \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ -3 \\\\ 3 \\\\ 1 \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f2785-4488-4c78-a8b9-d15ad5acd198",
   "metadata": {},
   "source": [
    "## The theorem\n",
    "\n",
    "### We are going to switch gears here to revisit solutions to ***inhomogeneous*** linear equations. Our solutions will now involve the column space and the nullspace.\n",
    "\n",
    "### For an inhomogeneous linear system $\\bf{A}\\bf{x} = \\bf{b}$, there are two possibilities:\n",
    "### 1. There are no solutions.\n",
    "### 2. There exists a solution.\n",
    "\n",
    "### Our first question is: for which vectors $\\bf{b}$ does $\\bf{A}\\bf{x} = \\bf{b}$ have a solution?\n",
    "\n",
    "### ***Example 6.1***\n",
    "### Consider the matrix equation\n",
    "## $$ \\bf{A}\\bf{x} = \\begin{pmatrix} 1 & 1 & 2 \\\\ 2 & 1 & 3 \\\\ 3 & 1 & 4 \\\\ 4 & 1 & 5 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{pmatrix} = \\bf{b} $$\n",
    "\n",
    "### For which vectors $\\bf{b}$ is there a vector $\\bf{x}$ so that $\\bf{A}\\bf{x} = \\bf{b}$? We can find some vectors directly.\n",
    "### - $\\bf{A}\\bf{x} = \\bf{0}$ always has the solution $\\bf{x} = 0$\n",
    "### - $\\begin{pmatrix} 1 & 1 & 2 \\\\ 2 & 1 & 3 \\\\ 3 & 1 & 4 \\\\ 4 & 1 & 5 \\end{pmatrix} \\bf{x} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} $ has a solution given $\\bf{x} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $\n",
    "### - $\\begin{pmatrix} 1 & 1 & 2 \\\\ 2 & 1 & 3 \\\\ 3 & 1 & 4 \\\\ 4 & 1 & 5 \\end{pmatrix} \\bf{x} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $ has a solution given $\\bf{x} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $\n",
    "\n",
    "### In particular, to figure out which vectors $\\bf{b}$ are possible, one option is to look at the vectors $\\bf{A}\\bf{x}$ for an vector $\\bf{x}$.\n",
    "### Recall that we can think of matrix vector multiplication as a linear combination of the columns of the matrix. \n",
    "### Since\n",
    "## $$ \\bf{A}\\bf{x} = \\begin{pmatrix} 1 & 1 & 2 \\\\ 2 & 1 & 3 \\\\ 3 & 1 & 4 \\\\ 4 & 1 & 5 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_ 3 \\end{pmatrix} = x_1 \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} + x_2 \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} + x_3 \\begin{pmatrix} 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix}  $$\n",
    "### the system $\\bf{A}\\bf{x} = \\bf{b}$ can be written as\n",
    "## $$ x_1 \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} + x_2 \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} + x_3 \\begin{pmatrix} 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix} = \\bf{b} $$\n",
    "\n",
    "### Given $\\bf{b}$, we can find $x_1$, $x_2$ and $x_3$ if and only if $\\bf{b}$ is a linear combination of the columns of $\\bf{A}$. Since the set of all linear combination of the columns of $\\bf{A}$ is called the column space, $\\operatorname{CS}(\\bf{A})$, this criterion can be rephrased as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab2f20-97ae-4c00-adbd-a72fcb376fc0",
   "metadata": {},
   "source": [
    "## Theorem 6.2\n",
    "### The linear system $\\bf{A}\\bf{x} = \\bf{b}$ has a solution if and only if $\\bf{b}$ is in $\\operatorname{CS}(\\bf{A})$.\n",
    "### This is why the column space is important!\n",
    "### This leads us to question, how we tell if $\\bf{b}$ is in $\\operatorname{CS}(\\bf{A})$ or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f295de-c323-4036-b61f-7cb3183ea7d1",
   "metadata": {},
   "source": [
    "## Interpreting an augmented matrix in row echelon form\n",
    "\n",
    "### Let's consider a linear system describing the intersection of two parallel planes in $\\mathbb{R}^3$\n",
    "## $$ \\begin{array} {rcl} x -3y+2z & = & 0 \\\\ x - 3y+2z & = & 1  \\end{array} $$\n",
    "### This system has no solutions. Let's see what happens when we try to solve it by elimination.\n",
    "### The augmented matrix is\n",
    "## $$ \\left( \\begin{array} {ccc|c} 1 & -3 & 2 & 0 \\\\ 1 & -3 & 2 & 1 \\end{array} \\right) $$\n",
    "\n",
    "### Subtracting the first row from the second puts the matrix in row echelon form\n",
    "## $$ \\left( \\begin{array} {ccc|c} 1 & -3 & 2 & 0 \\\\ {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{1}} \\end{array} \\right) $$\n",
    "### This row corresponds to the equation\n",
    "## $$ 0x+0y+0z=1 $$\n",
    "\n",
    "### uch an equation is never satisfied, so we say that the system is ***inconsistent***. In general, when an augmented matrix has a row echelon form that has a pivot in the augmented column, the original system has no solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc77a3-6096-45f1-abb3-1c4f4c63ddbc",
   "metadata": {},
   "source": [
    "### ***Example 6.3***\n",
    "### Consider the system of equations\n",
    "## $$ \\begin{array} {rcl} x_1 + 2x_2+2x_3+2x_4 & = & b_1 \\\\ 2x_1+4x_2+6x_3+8x_4 & = & b_2 \\\\ 3x_1+6x_2+8x_3+10x_4 & = & b_3 \\\\ 4x_1+8x_2+10x_3+12x_4 & = & b_4 \\end{array}  $$\n",
    "### The system has aumented matrix\n",
    "## $$ \\left( \\begin{array} {ccc|c} 1 & 2 & 2 & 2 & b_1 \\\\ 2 & 4 & 6 & 8 & b_2 \\\\ 3 & 6 & 8 & 10 & b_3 \\\\ 4 & 8 & 10 & 12 & b_4 \\end{array} \\right) $$\n",
    "\n",
    "### The first thing that we notice is that the third row is the sum of the first and second rows. This becomes apparent when we do Gaussian elimination since the third row becomes a row of zeros.\n",
    "## $$ \\left( \\begin{array} {ccc|c} 1 & 2 & 2 & 2 & b_1 \\\\ 2 & 4 & 6 & 8 & b_2 \\\\ 3 & 6 & 8 & 10 & b_3 \\\\ 4 & 8 & 10 & 12 & b_4 \\end{array} \\right) \\longrightarrow \\left( \\begin{array} {ccc|c} 1 & 2 & 2 & 2 & b_1 \\\\ 0 & 0 & 2 & 4 & b_2 - 2b_1 \\\\ 0 & 0 & 2 & 4 & b_3 - 3b_1 \\\\ 0 & 0 & 2 & 4 & b_4 - 4b_1 \\end{array} \\right) \\longrightarrow \\left( \\begin{array} {ccc|c} 1 & 2 & 2 & 2 & b_1 \\\\ 0 & 0 & 2 & 4 & b_2 - 2b_1 \\\\ {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{b_3 - b_1 - b_2}} \\\\ {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{0}} & {\\color{orange}{b_4 - 2b_1-b_2}} \\end{array} \\right) $$\n",
    "\n",
    "### The last two rows are represented by the equations\n",
    "## $$ \\begin{array} {rcl} 0x_1+0x_2+0x_3+0x_4 & = & b_3-b_1-b_2 \\\\ 0x_1+0x_2+0x_3+0x_4 & = & b_4-2b_1-b_2 \\end{array} $$\n",
    "\n",
    "### In other words, this system is solvable if and only if $b_3-b_1-b_2=0$ and $b_4-2b_1-b_2=0$. This shows us how to use our algorithm for finding solutions to linear systems to determine if a solution is solvable or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dc4b9-663d-4820-a53e-654acfa60a57",
   "metadata": {},
   "source": [
    "## Cool fact\n",
    "\n",
    "### There are two ways to describe a subspace of $\\mathbb{R}^m$. One is to give a basis for the subspace. The other is to describe the subspace as the set of vectors that satisfy a homogeneous linear system. Earlier we showed how to give a basis for the column space. This process of Gaussian elimination shows how to describe the column space as the set of $b_1,\\ldots,b_m$ satisfying a system of equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08efa29d-1746-4d00-8cae-bc413436dc92",
   "metadata": {},
   "source": [
    "## Algorithm to test if a linear system is consistent (has a solution):\n",
    "### Consider a linear system of $m$ equations in $n$ variables.\n",
    "### 1. Construct the $m \\times (n+1)$ augmented matrix\n",
    "### 2. Put it in row echelon form. Call this row echelon form $\\bf{B}$\n",
    "### 3. Look for a row that is all zero except for a nonzero entry in the augmented column. (Alternatively, find all of the pivots of $\\bf{B}$, and determine if there is a pivot in the augmented column.)\n",
    "### 4. If $\\bf{B}$ has a row that is all zero except for an entry in the augmented column, then one of the new equations has the form\n",
    "## $$ 0x_1 + \\ldots + 0x_n = \\underset{\\text{nonzero number}}{{\\color{red}{b}}} $$\n",
    " \n",
    "### So the linear system is ***inconsistent***. Otherwise, the system is ***consistent***.\n",
    "\n",
    "### If the system is consistent, then when solving it by back substitution, the free variables correspond to the non-pivot columns, excluding the augmented column, so\n",
    "## $$ \\# \\text{parameters in general solution} = \\underbrace{\\# \\text{non-pivot columns excluding the augmented column}}_{{\\color{orange}{\\text{\\# free variables}}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71779c-c1dd-447e-b54a-046901186883",
   "metadata": {},
   "source": [
    "## Worked example\n",
    "\n",
    "### ***Question 7.1***\n",
    "### Choose a value of $b$ for which the system is inconsistent, and another value of $b$ for which the system is consistent and has infinitely many solutions. What are two of those solutions?\n",
    "\n",
    "## $$  \\left\\{ \\begin{array} {rcl} 3x+2y & = & 10 \\\\ 6x+4y & = & b \\end{array} \\right. $$\n",
    "\n",
    "### ***Solution***\n",
    "### We put the system into augmented matrix form\n",
    "## $$ \\left( \\begin{array} {cc|c} 3 & 2 & 10 \\\\ 6 & 4 & b \\end{array} \\right) $$\n",
    "### We can eliminate the second equation by subtracting $2$ times the first equation from it, leaving us with\n",
    "## $$ \\left( \\begin{array} {cc|c} 3 & 2 & 10 \\\\ 0 & 0 & b - 20 \\end{array} \\right) $$\n",
    "### The second row reads $0\\cdot x+0\\cdot y = b - 20$. \n",
    "### If $b\\neq20$, then the equation can never be satisfied, in which case, there would be no solutions to the system. \n",
    "### If $b=20$, then there are infinitely many solutions to the system. The first row tells us that\n",
    "## $$ 3x+2y=10 $$\n",
    "### or that\n",
    "## $$ x+\\frac{2}{3}y=\\frac{10}{3} $$\n",
    "### Setting $y=c_1$ we see that\n",
    "## $$ x = \\frac{10}{3}-\\frac{2}{3}c_1 $$\n",
    "### so\n",
    "## $$ \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} \\frac{10}{3} \\\\ 0 \\end{pmatrix}  + c_1 \\begin{pmatrix} -\\frac{2}{3} \\\\ 1 \\end{pmatrix} $$\n",
    "\n",
    "### You should check to see if the two solutions you found can be written in this form. To get any one solution plug in a specific number for $c_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21606a-a7ba-452b-90e2-9ff89e7f01d9",
   "metadata": {},
   "source": [
    "## Inhomogeneous linear systems: structure of the solution set\n",
    "\n",
    "### Recall that for an inhomogeneous linear system $\\bf{A}\\bf{x} = \\bf{b}$, there are two possibilities:\n",
    "### 1. The vector $\\bf{b}$ is not in $\\operatorname{CS}(\\bf{A})$; there are no solutions.\n",
    "### 2. The vector $\\bf{b}$ is in $\\operatorname{CS}(\\bf{A})$; there exists a solution.\n",
    "\n",
    "### In case $2$ we describe the solution in terms of the nullspace of $\\bf{A}$ and any one solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae69f69-1584-4972-be86-2b6943431a23",
   "metadata": {},
   "source": [
    "### ***Working it out***\n",
    "\n",
    "### If an inhomogeneous equation has solutions, then we can express the general solution in terms of any one particular solution plus the general solution to the associated homogeneous equation: If $\\bf{x_p}$ is a particular solution to $\\bf{A}\\bf{x} = \\bf{b}$, and $\\bf{x_h}$ is the general solution to the homogeneous system $\\bf{A}\\bf{x} = \\bf{0}$, then $\\bf{x} \\colon = \\bf{x_p} + \\bf{x_h} $ is the general solution to $\\bf{A}\\bf{x} = \\bf{b}$.\n",
    "\n",
    "### ***Here is why it works***:\n",
    "### Suppose that a solution exists; let $\\bf{x_p}$ be one, so $\\bf{A}\\bf{x_p} = \\bf{b}$. If $\\bf{x_h} = \\bf{0}$, adding the two equations gives\n",
    "## $$ \\bf{A} (\\bf{x_p} + \\bf{x_h}) = \\bf{A}(\\bf{x_p}) + \\bf{A}(\\bf{x_h}) = \\bf{b} + \\bf{0} = \\bf{b} $$\n",
    "\n",
    "### so adding $\\bf{x_p}$ to $\\bf{x_h}$ produces a solution to inhomogeneous equation. Every solution $\\bf{x}$ to $\\bf{A}\\bf{x} = \\bf{b}$ arises this way.\n",
    "\n",
    "### This is analogous to the shape of solutions to inhomogeneous differential equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6749f12-e187-42bc-ae9e-07aece667ce9",
   "metadata": {},
   "source": [
    "### ***Problem 9.1***\n",
    "### The inhomogeneous linear system\n",
    "## $$ \\begin{array} {rcl} x+2y+2v+3w & = & {\\color{red}{4}} \\\\ -y+2z+3v+w & = & {\\color{red}{5}} \\\\ 2w & = & {\\color{red}{6}} \\end{array} $$\n",
    "\n",
    "### has augmented matrix\n",
    "\n",
    "## $$ \\left( \\begin{array} {ccccc|c} {\\color{red}{1}} & 2 & 0 & 2 & 3 & 4 \\\\ 0 & {\\color{red}{-1}} & 2 & 3 & 1 & 5 \\\\ 0 & 0 & 0 & 0 & {\\color{red}{2}} & 6 \\end{array} \\right) $$\n",
    "### in row echelon form.\n",
    "\n",
    "### Write the general solution to the system as one particular solution plus the general solution to the corresponding homogeneous system.\n",
    "\n",
    "### ***Solution***: \n",
    "### (We've solved this example before in the lecture on elimination. Let's review the process here quickly.) This system is already in row echelon form. Solve the equations in reverse order, and substitute into previous equations:\n",
    "\n",
    "## $$ {\\color{red}{w}} = 3 $$\n",
    "### There is no equation for $v$ in terms of the later variable $w$, so $v$ can be any number; set\n",
    "## $$ {\\color{orange}{v}} = c_1 \\quad \\text{for a parameter}\\, c_1 $$\n",
    "### There is no equation for $z$ in terms of $v$, $w$, so set\n",
    "## $$ \\begin{array} {rcl} {\\color{orange}{z}} & = & c_2 \\quad \\text{for a parameter }\\, c_2 \\\\ -y+2c_2+3c_1+3 & = & 5 \\\\ {\\color{red}{y}} & = & 3c_1+2c_2-2 \\\\ x+2(3c_1+2c_2-2) + 2c_1 +3(3) & = & 4 \\\\ {\\color{red}{x}} & = & -8c_1-4c_2-1 \\end{array}  $$\n",
    "\n",
    "### Conclusion: The general solution is:\n",
    "## $$ \\begin{pmatrix} {\\color{red}{x}} \\\\ {\\color{red}{y}} \\\\ {\\color{orange}{z}} \\\\ {\\color{orange}{v}} \\\\ {\\color{red}{w}} \\end{pmatrix} = \\begin{pmatrix} -8c_1-4c_2-1 \\\\ 3c_1+2c_2-2 \\\\ c_2 \\\\ c_1 \\\\ 3 \\end{pmatrix} = \\underbrace{\\begin{pmatrix} -1 \\\\ -2 \\\\ 0 \\\\ 0 \\\\ 3 \\end{pmatrix}}_{{\\color{red}{\\text{patricular solution}}}} \\underbrace{+ c_1 \\begin{pmatrix} -8 \\\\ 3 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}+ c_2 \\begin{pmatrix} -4 \\\\ 2 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}}_{{\\color{orange}{\\text{general homogeneous solution}}}} $$\n",
    "### where $c_1$, $c_2$ are parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500e1a5-9075-4c0d-8089-b1a9d39b8cdc",
   "metadata": {},
   "source": [
    "### ***Analogy with Solutions to Differential Equations***: \n",
    "### If $\\operatorname{p}(D)$ is a linear differential operator, then the general solution to $\\operatorname{p}(D) x = f$ is $x = x_p + x_h$, where $x_p$ is any particular solution, and $x_h$ is the general solution to the homogeneous equation $\\operatorname{p}(D) x = 0$. The general solution to a linear system $\\bf{A}\\bf{x} = \\bf{b}$ has the form $\\bf{x} = \\bf{x_p} + \\bf{x_h}$, where $\\bf{x_p}$ is a particular solution and $\\bf{x_h}$ is the general solution to the homogeneous system. The differential operator $\\operatorname{p}(D)$ is the analogue of the matrix $\\bf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b2342-b106-4180-9a61-4cfd16989f55",
   "metadata": {},
   "source": [
    "## Composition and matrix multiplication\n",
    "\n",
    "### Suppose that we have two functions from $\\mathbb{R}^2$ to $\\mathbb{R}^2$. The first rotates all points 90 degrees counter clockwise about the origin. The second reflects across the $x$-axis. Both of these functions can be represented by a matrix.\n",
    "## $$ \\begin{array} {lr} \\text{90 degree rotation counterclockwise:} & \\text{Reflection across x-axis:} \\\\ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\longrightarrow \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} & \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\longrightarrow \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\\\ \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\longrightarrow \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix} & \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\longrightarrow \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix} \\\\ \\bf{B} = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} & \\bf{A} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\end{array} $$\n",
    "![Rotation](img/rotation-2.png)\n",
    "\n",
    "### We can compose these two functions, first rotating 90 degrees counterclockwise, and then reflecting across the $x$-axis.\n",
    "![Rotation](img/rotation-3.png)\n",
    "\n",
    "### But what matrix represents this composed function? One way is to figure it out by seeing where each of the standard basis vectors is sent by the composition.\n",
    "\n",
    "## $$ \\begin{array} {rcccl} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\left[ \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right] & = & \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} & = & \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix} \\\\ \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\left[ \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\right] & = & \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix} & = & \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix} \\end{array} $$\n",
    "\n",
    "### Therefore the matrix representing the composed matrix is\n",
    "## $$ \\begin{pmatrix} 0 & -1 \\\\ -1 & 0 \\end{pmatrix} $$\n",
    "\n",
    "### There is an easier way to figure out what the composed matrix is in terms of the original two matrices. And that's the matrix product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e572d4f-f32c-4955-a459-70ab0a9d77f0",
   "metadata": {},
   "source": [
    "## Defining the matrix product\n",
    "\n",
    "### Suppose $\\bf{A}$ is an $m \\times n$ matrix, and $\\bf{B}$ is an $n \\times p$ matrix. Starting with a vector $\\bf{v}$ in $\\mathbb{R}^p$, applying left multiplication by the matrix $\\bf{B}$ gives a vector in $\\mathbb{R}^n$. Then applying left multiplication by $\\bf{A}$ gives a vector in $\\mathbb{R}^m$. This composition of functions defines a new function sending the vector $\\bf{v}$ to $\\bf{A}(\\bf{B}\\bf{v})$.\n",
    "\n",
    "![Product](img/product.png)\n",
    "\n",
    "### This composition function itself can be viewed as left multiplication by some matrix. What is it? The answer is called the matrix product $\\bf{A}\\bf{B}$. The matrix product $\\bf{A}\\bf{B}$ is characterized by the property\n",
    "## $$ (\\bf{A}\\bf{B})\\bf{v} = \\bf{A}(\\bf{B}\\bf{v}) \\quad \\text{for all vectors }\\, \\bf{v} \\, \\text{in}\\, \\mathbb{R}^p $$\n",
    "### The matrix product $\\bf{A}\\bf{B}$ is defined if and only if the number of columns of $\\bf{A}$ is equal to the number of rows of $\\bf{B}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26b10b-9fbf-4b12-b60a-1fae2bdb2ea3",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "### Let us illustrate matrix multiplication with an example.\n",
    "\n",
    "### ***Example 10.1***\n",
    "### Multiply a $2 \\times 3$ matrix by a $3 \\times 2$ matrix:\n",
    "## $$ \\begin{pmatrix} {\\color{orange}{2}} & {\\color{orange}{4}} & {\\color{orange}{1}} \\\\ {\\color{red}{-3}} & {\\color{red}{5}} & {\\color{red}{-1}} \\end{pmatrix} \\begin{pmatrix} x & u \\\\ y & v \\\\ z & w \\end{pmatrix} = \\begin{pmatrix} {\\color{orange}{2}}x+{\\color{orange}{4}}y+{\\color{orange}{1}}z & {\\color{orange}{2}}u + {\\color{orange}{4}}v+{\\color{orange}{1}} \\\\ {\\color{red}{-3}}x+{\\color{red}{5}}y {\\color{red}{-1}}z & {\\color{red}{-3}}u+{\\color{red}{5}}v {\\color{red}{-1}}w \\end{pmatrix} $$\n",
    "\n",
    "### The product is a $2 \\times 2$ matrix. The $i,j$-entry of a matrix is the entry in the $i$th row and $j$th column of the matrix.\n",
    "\n",
    "### Consider two matrices\n",
    "## $$ \\mathbf{A}= \\begin{pmatrix}  a_{11} &  a_{12} &  \\cdots & & \\cdots &  a_{1n} \\\\ a_{21} &  a_{22} &  \\cdots & & \\cdots &  a_{2n} \\\\ \\vdots &  \\vdots &  \\ddots & & &  \\vdots \\\\ & & & a_{ij}  & & \\\\ \\vdots &  \\vdots & & & \\ddots &  \\vdots \\\\ a_{m1} &  a_{m2} &  \\cdots & & \\cdots &  a_{mn} \\end{pmatrix} \\qquad \\qquad \\mathbf{B}= \\begin{pmatrix}  b_{11} &  b_{12} &  \\cdots & & \\cdots &  b_{1p} \\\\ b_{21} &  b_{22} &  \\cdots & & \\cdots &  b_{2p} \\\\ \\vdots &  \\vdots &  \\ddots & & &  \\vdots \\\\ & & & b_{ij}  & & \\\\ \\vdots &  \\vdots & & & \\ddots &  \\vdots \\\\ b_{n1} &  b_{n2} &  \\cdots & & \\cdots &  b_{np} \\end{pmatrix} $$\n",
    "\n",
    "### The $i,j$-entry of the product $\\bf{A}\\bf{B}$ is the dot product of the $i$th row of $\\bf{A}$ and the $j$th column of $\\bf{B}$. For example, the entry in the third row and second column of $\\bf{C}=\\bf{A}\\bf{B}$ is the product of the third row of $\\bf{A}$ and the second column of $\\bf{B}$:\n",
    "## $$ c_{32} = \\begin{pmatrix} a_{31} & a_{32} & \\cdots & a_{3n} \\end{pmatrix} \\begin{pmatrix} b_{12} \\\\ b_{22} \\\\ \\vdots \\\\ b_{n2} \\end{pmatrix} = a_{31}b_{12}+a_{32}b_{22}+\\ldots+a_{3n}b_{n2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94349e0b-bd71-4650-b662-c8c725a90a94",
   "metadata": {},
   "source": [
    "## Another prespective\n",
    "\n",
    "### We can also compute the matrix product one column at a time. Multiplying $\\bf{A}$ by (the $j$th column of $\\bf{B}$) gives (the $j$th column of $\\bf{C}=\\bf{A}\\bf{B}$).\n",
    "## $$ \\bf{A}(\\text{the }\\,j\\text{th column of }\\,\\bf{B}) = \\text{the}\\,j\\text{th column of}\\,\\bf{C} $$\n",
    "### This shows that each column of $\\bf{C}$ is a linear combination of the columns of $\\bf{A}$. The coefficients of that linear combination are the entries in the the corresponding column of $\\bf{B}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896ed8a-4fd7-44d3-a289-44b18547f9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
